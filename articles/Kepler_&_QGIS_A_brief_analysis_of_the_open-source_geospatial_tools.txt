Let’s start with why.

Why do we need geospatial analysis? Why does it matter now more than ever?

Human brain recognizes information mostly based on time, date, and location. For example, “Remember we met yesterday at the theatre?” or “Where are you now?” followed by “I am at the university”.

With the help of today’s technologies — cellphones, GPS, social media, and more — one can collect geo-referenced (time and place) data of practically any event occurring around them, or even globally.

Geospatial analysis is leveraging this data into building maps, cartograms, statistics, and graphs, to show how changes are taking place and where exactly. Representing data on a large scale can reveal major transformation evolving around us, such as climate change. Applications of geospatial analysis include — but not limited to — demands-supply matching, climate change modeling, geo-marketing, better ETA estimations, and human population forecasting.

Today, companies mostly use open source tools like Kepler.gl and QGIS. While these tools are really good for certain aspects of geospatial analysis, they need to work in other aspects. Let’s explore it in a bit of detail.

Kepler.gl

Kepler is a web-based platform to visualize large-scale location data. It was created by the visualization team at Uber with the mission to create industry-grade open source frameworks to supercharge big data. There are four major suits available — Deck, Luma, React map and React vis — to make beautiful data-driven maps. Kepler was built with deck.gl and utilizes WebGL (A JavaScript API) to render large data faster and efficiently.

Kepler is merely a visualization tool. But just like robots, it is damn good at doing that particular job efficiently. It takes CSV, JSON, and geoJSON files. The basic flow of Kepler is you perform some operations on your database on your local machine, download if not on the local machine and plot it on Kepler.