Today, we spend a good part of our day talking to people online, through text, twitter DMs, and email. Rarely do we doubt that the person on the other end of the message understands us when we talk. Further, if I call to get haircut later this week, I don’t wonder if the person on the other end of the line is a person… until now.

What if that person isn’t a person at all, but a chat bot or the google assistant? If the chat bot responds intelligently it would follow that they are intelligent and I would be none the wiser assuming that they are a person. The google assistant understands me, and that I want a haircut Thursday, but I also have an opening Friday (because there is nothing scheduled on my google calendar). So if the barber shop is booked Thursday, Friday is a good alternative.

It’s 2019, has a machine passed the Turing Test?

Google I/O 2018

Yes — depending on how you frame the test.

This 55 second call was over fifty years in the making, starting with Turing’s paper and continuing with Natural Language Processing (NLP) programs such as ELIZA and A.L.I.C.E. (winner of The Loebner Prize). Passing the Turing Test is akin to answering Turing’s question “Can machines think?” with a yes. But, is this a claim we can actually make? Is all intelligence is appearing intelligent on an online chat or phone call? Does A.L.I.C.E. think or feel about the responses to my questions?

To test this let’s take another example.

The Narrow Argument and the Chinese Room

Imagine that a native English speaker who knows no Chinese is locked in a room full of boxes containing Chinese symbols (a database) together with a book of instructions for manipulating the symbols (the program). Imagine that people outside the room send in other Chinese symbols which, unknown to the person in the room, are questions in Chinese (the input). By following the instructions in the book, the person in the room is able to pass out Chinese symbols (the output) which are the correct answers to the questions. This person passes the Turing Test without understanding a word of Chinese.

In other words, while the google assistant can give you the right responses, the assistant doesn’t understand those responses in a meaningful way; it just makes a calendar event.

John Searle published this argument in 1980, leading him to make the distinct between strong and weak AI. Strong AI is the claim that computers have mental capabilities and are not only able to understand games such as chess, but natural language. Weak AI is the claim that computers simulate mental abilities, allowing us to use them in psychology, linguistics, and chess training software, but there is no understanding. The narrow argument follows as