It has been a few months since I started working on backtesting quantitative trading. Initially, all the focus was on the core activities: strategies and which backtesting engines shall be used, but as soon as the project started to roll over, other real-world small challenges appeared demanding attention.

The endeavour of systematically and professionally approach backtesting requires not only the fancy activities of machine learning, statistical analysis and data analytics, but also a bit of humble scaffolding and plumbing on the data warehouse stage.

In my previous post How to store financial market data for backtesting, I was discussing the retrieval strategies to be used for backtesting. Using conventional actual warehouse terminology, if in that article we discussed the data pickup challenges in this article we discuss the data putaway strategies.

Provisioning and feeding data into your warehouse deals with the less shiny but equally relevant side of the data analysis business: keeping the raw data flowing, because without proper quality data feeds, missions are doomed to failure.

In-house vs. external provider

There are basically two approaches that can be followed:

Contract a third party data feed supplier and consume their APIs as required. There will be integration costs, but you do not need to build, feed or operate your own data warehouse. Stockpile data from different sources in your own data warehouse. There will be integration costs, plus the costs associated to build, maintain and operate your data warehouse.

While the first option shall ensure consistent and quality data (provided that you select a quality data feed provider) it suffers from several limitations: