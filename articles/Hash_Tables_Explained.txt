Hash Tables Explained

I ntroduction

When given large datasets defined by pieces of information that are related to other pieces of information, what are some ways we can store and retrieve information efficiently? To manage large quantities of relational data, we need to have data structures that have the capability quickly manipulate it (i.e. Insert, Delete, and Search). Suppose we had “key” data that corresponded with “value” data, then, one way to relate two pieces of information is to use a dictionary which is composed of key/value relationships. There are a few different ways to implement a dictionary, including using balanced binary search trees and doubly linked lists. In this article, we will talk about using hash tables, which is, by far, the fastest method of the three dictionary implementations and can perform insert, delete and search operations more efficiently than the other two dictionary implementations.

What is the motivation for a hash function?

First, I’m going to explain why we need something other than the simplest solution to relating information, known as the Direct Address Table. This naive solution is basically an array of size m, where the number of keys are less than m, and the address of each array index corresponds to the key, which either holds the value or holds a pointer to the value. Example: We can store the value associated with key k in the kth slot. Addresses that don’t have corresponding keys are simply known as: nil. See relation below between keys and values, as defined by the Direct Address Table (T).

How a Direct Address Table works

Insertion, Deletion, and Search are all O(1) in this case as you can go directly to the key through the address, and access the value. However, the two assumptions that limit the usage of this data structure for storing relational information is that:

The size of the array, m, is not too large. No two elements have the same key.

The first is a problem because we don’t want the array to take up too much space with nil elements. The second is also a problem because it limits the types of keys we can use.

So instead, we use a hash function.

What is a hash function?

A hash function, h(k), is a function that maps all the keys to the slots of an array. Another way to think about it is: given a key and an array, the hash function can make a suggestion as to where the index of the key should be stored in the array.

How does a hash function work?

There are several hash functions that can be implemented for a Hash Table, but the most prevalent one is the Division Method, where h(k) = k mod m, for some value of m. Other hashing functions include: the Multiplication Method and the Folding Method.

What is a hash collision and how do I resolve a hash collision?

So this is all good and well. But what happens when a key is hashed into the same array slot as another key? Aha! THIS is known as a hash collision. There are a few different ways of dealing with a hash collision, the most popular two ways are Open Addressing and Closed Addressing.

Open addressing is when you place an item some where other than its calculated position. We do this in a calculated way, such as linear probing, where a linear search is used to find an available slot and finding an item also involves a linear search.

How the Linear Probe works as an example of open addressing

Here’s a code snippet of a linear probe in a hash table:

class HashEntry:

def __init__(self, key, value):

self.key = key

self.value = value

self.next = None class HashTable:

def __init__(self, size):

self.size = size

self.keys = [None] * self.size

self.values = [None] * self.size



def hash_function(self, key):

return hash(key) % self.size



def get_slot(self, key):

slot = self.hash_function(key)

while self.keys[slot] and self.keys[slot] != key:

slot = self.hash_function(slot + 1)

return slot



def set(self, key, value):

slot = self.get_slot(key)

self.keys[slot] = key

self.values[slot] = value



def get(self, key):

return self.values[self.get_slot(key)]

Another way of open addressing is using quadratic probing, where we square the number of the foiled attempts when deciding how far from the point of original collision to look next. Each time another foiled attempt is made, the distance from the original point of collision grows rapidly.

Closed Addressing is essentially using linked lists to chain together keys that have the same hash value. The look-up for this method is the same as searching through a linked list.

Chaining uses Linked Lists to resolve hash collisions

Here’s a code snippet of chaining in a hash table:

class HashEntry:

def __init__(self, key, value):

self.key = key

self.value = value

self.next = None class HashTable:

def __init__(self, size):

self.size = size

self.table = [None] * self.size def hashing_function(self, key):

return hash(key) % self.size def rehash(self, entry, key, value):

while entry and entry.key != key:

prev, entry = entry, entry.next

if entry:

entry.value = value

else:

prev.next = HashEntry(key, value) def set(self, key, value):

slot = self.hashing_function(key)

entry = self.table[slot]

if not entry:

self.table[slot] = HashEntry(key, value)

else:

self.rehash(entry, key, value)



def get(self, key):

hash = self.hashing_function(key)

if not self.table[hash]: raise KeyError

else:

entry = self.table[hash]

while entry and entry.key != key: entry = entry.next

return entry.value

That’s all for now! I hope that this tidbit of information about Hash Tables and their collisions have inspired you to learn more about them.

Resources and Citations

Hash Tables and Hash Functions: https://www.youtube.com/watch?v=KyUTuwz_b7Q

MIT OpenCourseWare: https://www.youtube.com/watch?v=0M_kIqhwbFo

Stanford CS 161 Notes on Hashing: https://web.stanford.edu/class/archive/cs/cs161/cs161.1168/lecture9.pdf

Coding Cheat Sheets: https://www.alispit.tel/coding-cheat-sheets/data_structures/hash_tables.html