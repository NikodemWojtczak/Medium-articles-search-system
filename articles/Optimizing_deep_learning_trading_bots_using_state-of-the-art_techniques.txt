In the last article, we used deep reinforcement learning to create Bitcoin trading bots that don’t lose money. Although the agents were profitable, the results weren’t all that impressive, so this time we’re going to step it up a notch and massively improve our model’s profitability.

As a reminder, the purpose of this series of articles is to experiment with state-of-the-art deep reinforcement learning technologies to see if we can create profitable Bitcoin trading bots. It seems to be the status quo to quickly shut down any attempts to create reinforcement learning algorithms, as it is “the wrong way to go about building a trading algorithm”. However, recent advances in the field have shown that RL agents are often capable of learning much more than supervised learning agents within the same problem domain. For this reason, I am writing these articles to see just how profitable we can make these trading agents, or if the status quo exists for a reason.

We will first improve our model’s policy network and make the input data set stationary, so we can learn more from less data. Next, we will use advanced feature engineering to improve our agent’s observation space and fine tune our reward function to produce more attractive strategies. Finally, we will use a technique called Bayesian optimization to zone in on the most profitable hyper-parameters, before training and testing the final agents profitablity. Hold on to your seats everyone, this is going to be a wild ride.

When you’ve read this article, check out TensorTrade — the successor framework to the codebase produced in this article.

Modifications

The first thing we need to do to improve the profitability of our model, is make a couple improvements on the code we wrote in the last…