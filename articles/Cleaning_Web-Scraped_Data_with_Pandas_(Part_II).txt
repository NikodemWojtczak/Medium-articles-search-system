Member-only story Cleaning Web-Scraped Data with Pandas (Part II)

This post is a continuation of my previous discussion on cleaning Web-Scraped data. You can access Part I with the link below:

|| I || Quantity vs. Quality (of data)

As I mentioned in my previous post, cleaning data is a prerequisite to machine learning. Measuring the sanity of your data can also give you a good indication of how precise or accurate your model would be. When it comes to web-scraped data, you would often lose a lot of information in the process of cleaning. So what should it be? Quantity or Quality?

Photo by JOSHUA COLEMAN on Unsplash

It’s not easy to answer the question, as it can really depend on the case and the process mapped out by a data scientist.

If you end up working with data that requires less specificity to work with its variables, then you may choose to go with quantity, and should be fine with using data cleansing methods that may replace values using inferential data.

However, if you’re working with data that does require specificity. For example, in this case, we’re working with Laptop data. It wouldn’t make sense to use mean, median, or mode to replace missing values in our data since there are multiple categories of laptops with different combinations of specs. For example, if i5 is the mode of column “processor”, you can’t let all the missing values be equal to i5 as this would skew the data, creating a large bias.

Therefore, you would clean the data by removing the rows with missing values. This would reduce your data from 440 values to 153 values. I know that’s not great for a machine learning model but as a data scientist, I understand that the quality of my results will be tied to the quality of my…