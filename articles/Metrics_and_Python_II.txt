You can download complete file in https://kreilabs.com/wp-content/uploads/2019/12/Metrics_table.pdf

Here we can see pyhton implementation for table metrics in matrix_metrix routine:

import sklearn.metrics

import math def matrix_metrix(real_values,pred_values,beta):

CM = confusion_matrix(real_values,pred_values)

TN = CM[0][0]

FN = CM[1][0]

TP = CM[1][1]

FP = CM[0][1]

Population = TN+FN+TP+FP

Prevalence = round( (TP+FP) / Population,2)

Accuracy = round( (TP+TN) / Population,4)

Precision = round( TP / (TP+FP),4 )

NPV = round( TN / (TN+FN),4 )

FDR = round( FP / (TP+FP),4 )

FOR = round( FN / (TN+FN),4 )

check_Pos = Precision + FDR

check_Neg = NPV + FOR

Recall = round( TP / (TP+FN),4 )

FPR = round( FP / (TN+FP),4 )

FNR = round( FN / (TP+FN),4 )

TNR = round( TN / (TN+FP),4 )

check_Pos2 = Recall + FNR

check_Neg2 = FPR + TNR

LRPos = round( Recall/FPR,4 )

LRNeg = round( FNR / TNR ,4 )

DOR = round( LRPos/LRNeg)

F1 = round ( 2 * ((Precision*Recall)/(Precision+Recall)),4)

FBeta = round ( (1+beta**2)*((Precision*Recall)/((beta**2 * Precision)+ Recall)) ,4)

MCC = round ( ((TP*TN)-(FP*FN))/math.sqrt((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN)) ,4)

BM = Recall+TNR-1

MK = Precision+NPV-1 mat_met = pd.DataFrame({

'Metric':['TP','TN','FP','FN','Prevalence','Accuracy','Precision','NPV','FDR','FOR','check_Pos','check_Neg','Recall','FPR','FNR','TNR','check_Pos2','check_Neg2','LR+','LR-','DOR','F1','FBeta','MCC','BM','MK'], 'Value':[TP,TN,FP,FN,Prevalence,Accuracy,Precision,NPV,FDR,FOR,check_Pos,check_Neg,Recall,FPR,FNR,TNR,check_Pos2,check_Neg2,LRPos,LRNeg,DOR,F1,FBeta,MCC,BM,MK]}) return (mat_met)

When we call matrix_metrix function:

beta = 0.4

mat_met = matrix_metrix(real_values,pred_values,beta)

print (mat_met)

Note: Prevalence is 0.505, code has a mistake at first version

Predicted and real values

TP = True positive

TN = True negative

FP = False positive — Equivalent with false alarm or Type I error¹

FN = False negative — Equivalent with miss or Type II error ²

Total rates*

Prevalence: Serves to measure the balance of data within the total population.

It is possible to measure the prevalence of positives or negatives and the sum of both quotients is = 1, a balanced data set would give coefficients close to 0.5

If, on the contrary, one of the factors is close to 1 and the other to 0, we are going to have an unbalanced data set.

Accuracy: It is the measure of success of the system, the total of positive and negative achievements over the total population, indicates the degree of success of the model. According to the cost of the sensitivity³ of the case study, and the balance of the data (prevalence).

Predicted rates*

PPV — Positive predictive value o precisión

NPV — Negative predictive value

The PPV and NPV describe the performance of a diagnostic test or other statistical measure. A high result can be interpreted as indicating the accuracy of such a statistic. The PPV and NPV are not intrinsic to the test; they depend also on the prevalence. ⁴

FDR — False Discovery rate (Type I) [iv]

FOR — False Omission Rate

check_Pos: PPV + FDR = 1

check_Neg: FOR + NPV = 1

Condition rates*

Recall, sensitivity, probability of detection, and power are the same measure, which assumes different names and applications depending on the field of study.

In the literature referring to binary classification problems, the use of the term recall is more frequent.

“Sensitivity and specificity are statistical measures of the performance of a binary classification test, also known in statistics as a classification function, that are widely used in medicine: · Sensitivity measures the proportion of actual positives that are correctly identified as such. · Specificity (also called the true negative rate) measures the proportion of actual negatives that are correctly identified as such (e.g., the percentage of healthy people who are correctly identified as not having the condition).⁵

FPR — false positive ratio (or false alarm ratio) is the probability of falsely rejecting the null hypothesis for a particular test.

FNR — false negative rate is the proportion of positives which yield negative test outcomes with the test, i.e., the conditional probability of a negative test result given that the condition being looked for is present.

In statistical hypothesis testing, this fraction is given the letter β. The “power” (or the “sensitivity”) of the test is equal to 1−β.

Combinated rates*

Not to be confused with Likelihood-ratio test.

LR (+ -) Likelihood ratios: They are used for assessing the value of performing a diagnostic test. ⁶

DOR — diagnostic odds ratio is a measure of the effectiveness of a diagnostic test ⁷