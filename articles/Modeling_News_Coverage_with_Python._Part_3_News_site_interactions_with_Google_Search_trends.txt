Fitting models of Google Search to Search Trends and News Articles

This post integrates data from a limited sample of newspaper coverage with Google Search trends to model interactions between the two. In these examples, the preliminary analysis finds news coverage useful for forecasting search trends but small and mixed results in the other direction. These examples were selected to be done with limited resources and time in a blog post, but everything’s general purpose enough that you can swap in your own topics or data and it should be enough to get you started.

This is the third post in a series of blog posts demonstrating modeling news with Python. The first post of this series looked at what time series were and interactions within a medium can be modeled. The second post looked at news coverage of a few publications and themes to forecast coverage with different methods.

Loading Articles

As before, all the necessary code for the models is provided in this post. It’s formatted to be copied and pasted into a Jupyter Notebook file. The code will acquire the article data, but you will want to follow the instructions and link to download the Google Search trend data or just download it yourself if you’re familiar with it.

We’ll start by going and pulling 60 days of articles from GDELT using a Python package (https://www.gdeltproject.org/data.html#rawdatafiles). These articles are labelled with topics, personalities, and locations. This checks if the files are already downloaded and if not, downloads them, and formats them into a pandas dataframe so that we can manipulate the series.

So now we’ll run it through a SARIMA model with parameters like we eyeballed last time. In the last post, we used the mean square error to evaluate accuracy but this time we’ll use the mean absolute percentage error (MAPE). This lets us normalize error across time series of different values. We’ll keep track of the MAPE values in the mape_df dataframe to be able to compare results.

The first model we test will use both coverage of other countries within the publication and coverage of that country in other publication to fit against as done previously to make sure everything works again.

We can then change the exogenous series and only select articles from within the same publication to fit the model with instead, saving the results to the mape_df dataframe column “WithinNewspapersOnly_predicted”.

We can compare the difference in the mape_df betweeen the two:

mape_df["news_dif"] = mape_df["WithinNewspapersOnly_predicted"] - mape_df["NewspapersOnly_predicted"] for country in myCountries:

print("{} mean hat change of {}".format(country, mape_df[mape_df.index.map(lambda x: x.find(country) > -1)]["news_dif"].mean())) >>> dprk mean hat change of -10.75

>>> ukraine mean hat change of -1.5

>>> russia mean hat change of 6.5

>>> iran mean hat change of -3.0

>>> china mean hat change of -13.75

It looks as though using only the same publication outperforms using coverage from other publications most of the time. That being said, that’s for this dataset and a small period of coverage. Alright, so what happens with Google Search trends? In the next step we fit a model to the search trends, and then after that fit the news model to the news data and the search trends.

Google Search Trends

We first need to get the Google search data. Google publishes their search trends at https://trends.google.com. There’s lots of fun features there if you aren’t familiar with it. To speed things up, I went and searched for the trends on the relevant countries (North Korea, China, Russia, Iran, and Syria) from 8/8/2019 to 10/6/2019 at this link.

The page should look as follows:

Google Trend Search Results

Google gives search trends as percents relative to the highest searched term in the search queries as opposed to raw search numbers. Here, Ukraine received the highest amount of search result so all the other data points follow as a percent of Ukraine’s maximum search. We can download this in CSV format by clicking the down arrow to the right of the “Interest over time” label.

We can then put the CSV into our current working directory (or some other location if you want to change the code) and load it in with pandas. Note: The first row of Google’s CSV is some sort of metadata label, so we skiprows it to get it the columns formatted properly when loading.

gdata = pd.read_csv("multiTimeline.csv", skiprows=2)

gdata.plot()

Visual inspection shows it looks the same as the original data on the website, so it seems to have loaded properly. Now, we can format it to be the same as our news media data frame before and put them together, creating a copy of the original time_series df as original just in case we mess something up and need to go back.

gdata.columns = [x.replace(": (United States)", "").replace("North Korea", "dprk").lower() for x in gdata.columns] gdata.day = pd.to_datetime(gdata.day) gdata.set_index("day", inplace=True, drop=True) original = time_series.copy() time_series = time_series.join(gdata)

And so now we can just go ahead and plot both the newspaper coverage and the Google Search trends to visually check how much they line up.

We can make a few observations to begin with. There’s a clear weekly seasonality with some of the search trends (e.g. China), but with the others (e.g. Ukraine, Iran), the seasonality isn’t as important as those big spikes that show up with increased news coverage. This variance is going to be a bit problematic because the search seems to ignore news coverage trends for DPRK, react to the second spike with Ukraine, and react to the third spike with Iran.

We can check quickly if there’s an effect from the news on search. To just establish baseline error rates, we can go ahead and run the same SARIMA models on the search results as the news sites, using only previous Google Search trends and news media coverage of the same topic for the models.

North Korea and Ukraine have the most error at this point. As we’d seen earlier, the Google search had diverged from the news results. Sure enough, the model learned from the first Ukraine spike and predicted that the search trends would spike again when they didn’t. Also, the search trends kind of ignore the news content as well for North Korea. We don’t really have anything to predict that sort of behavior in this data, so not going to bother doing decomposition but longer periods of data might let us know how normal that is.

Since total article count per day will generally be around the same for each publication, covering one country might lead to a decrease in coverage of another country (except where both are covered in the same article), so we can see if just including everything improves the model.

It looks like throwing in all the other time series improved the predictions on North Korea and Ukraine while having no effect on Russia and negative effects on Iran and China. A longer amount of time would definitely help massage out what kind of data we really want but I don’t want to get into building a database in these blog posts and it gets the point across enough.

It looks like news trends help us predict search trends. Does the reverse hold?

Adding Google Search back into the News Model

So far we’ve looked at how news predicts Google search trends. But what about the other way around?

Since we already added the Google Search trends into the time_series dataframe, we can just re-run the original code, modifying it slightly to only include newspapers and then the dataframe column save the MAPE values into .

We can check how the new model differs in accuracy from the original,

mape_df["overall_change"] =mape_df["WithSearch_predicted"] - mape_df["NewspapersOnly_predicted"] for country in myCountries:

print("{} mean hat change of {}".format(country, mape_df[mape_df.index.map(lambda x: x.find(country) > -1)]["overall_change"].mean())) >>> dprk mean hat change of 0.25

>>> ukraine mean hat change of -2.5

>>> russia mean hat change of 7.0

>>> iran mean hat change of 5.0

>>> china mean hat change of -2.25

With these parameters and this data, adding in the Google Search trends has mixed but small impacts on the model. That’s fine though, with 60 days of data we’re not expecting great results anyway.

In Closing

We saw that sometimes the news can help predict Google Search Trends but not always. SARIMA models did worse on the topics where search trends diverged from news coverage trends, which should be expected. Without previous examples for the Ukraine spike, we wouldn’t expect the model to really guess that the coverage would diverge that much.

We did not get great results from adding the search results back into the news models. That’s fine. The parameters on the models weren’t tuned to the specifics of any of the search terms and the period of time covered is pretty short. It would be interesting to see how both the news -> search and search -> news relationships hold up over longer periods of time. Furthermore, these are pretty broad subjects. In the next post, we’ll look at the trends in the sub-themes publications cover within each of these issues.