Exercise Classification with Machine Learning (Part II)

In this two-part post we’re taking a deep dive into a specific problem: classifying videos of people performing various exercises. Trevor Phillips · Follow Published in Towards Data Science · 6 min read · Jul 29, 2019 -- 2 Share

In the last post, we focused on a more algorithmic approach using k-Nearest Neighbors to classify an unknown video. In this post, we’ll look at an exclusively machine learning (ML) approach.

Code for everything we’re going to cover can be found on this GitHub repository. The algorithmic approach (Part I) is written in Swift and is available as a CocoaPod. The ML approach (Part II) is written in Python/TensorFlow and can be found as part of the GitHub repository.

Background

Classifying videos is fundamentally different from image classification in that we must consider the time dimension. Whatever ML model we use, it needs to learn features that have a temporal component. There have been various architectures developed for this purpose, some of which we’ll touch upon now.

Recurrent Neural Networks (RNNs)

Unrolled RNN with many-to-one architecture (source)

RNNs are great for sequences of input data such as text or, in our case, frames of a video. Each step of the RNN is a function of the input at a particular point in time, as well as the “hidden state” of the previous step. In this manner, the RNN is able to learn temporal features. Weights and biases are typically shared between steps.

The downside of RNNs is that they often suffer from vanishing/exploding gradient problems. Additionally, backpropagation is computationally expensive because we must propagate through all steps in the network.

Long Short Term Memory Networks (LSTMs)

LSTMs are a more complex variant of vanilla RNNs designed to capture long-term dependencies. One “cell” of a LSTM contains 4 trainable gates: