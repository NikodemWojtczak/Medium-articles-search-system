For the second consecutive year, I was lucky enough to attend the TensorFlow dev Summit on March 6th — 7th at the Google Event Center in Sunnyvale, California USA. Last year, I was impressed by the organization, the venue, the schedule, the speakers and I think this year was even better. So once again, congratulations to the Google and TensorFlow teams for organizing such an amazing event!

TensorFlow Dev Summit still brings together a diverse mix of machine learning users from around the world; now for two days instead of one. The first day was full of technical talks, demos, new product announcements and other improvements to the framework, whereas the second day focused on lightning talks, hands-on sessions where attendees can code along with the TensorFlow team members.

There are a number of interesting things to say about this event so in this post, I will share my personal notes and briefly summarize what has caught my attention the most.

Day 1- March 6th

TensorFlow 2.0

In TensorFlow 2.0, the focus has been around making the API simpler, and more natural. The API components integrate better with Keras and, by default, the eager mode is activated. With 2.0, you can use Keras as you know it, building your models with the Sequential API, and then using compile and fit. Keras’s fit() will work for many cases; however, if needed, many more options are available. In the recent past, you needed to be familiar with tf.where, tf.select in order to write the conditions and it could have been hard to write a complex control flow as a TensorFlow graph. With 2.0, you can simply use the decorator @tf.function to write a complex control flow as TensorFlow graph. tf.function is just decorator to be attached to the Python function. TensorFlow compiler automatically resolves the dependency on the Tensor and creates the appropriate graph. That makes the development far easier to understand and use since we can now write the control flow of TensorFlow graphs as we write a “standard” Python code.

a = tf.constant([1, 2])

b = tf.constant([3, 4])

print(a + b)

# returns: tf.Tensor([4 6], shape=(2,), dtype=int32)

The magic is achieved under the hood by overloading some method like __if__ or __while__ for example. So overall you do not need to write anymore :

tf.session.run

tf.control_dependencies

tf.global_variables_initializer

tf.cond, tf.while_loop

Along with the 2.0, the team also launched TensorFlow Datasets, a collection of commonly used ML datasets prepared and exposed as tf.data.Datasets or NumPy arrays for easy use in TensorFlow. In addition, they also provide conversion and migration tools to help with the transition from 1.x code to 2.0.

TensorFlow Datasets & TensorFlow Probability

Others add-ons and extensions :

TensorFlow Agents: library for reinforcement learning

TF Federated : a library for federated learning to take advantage of decentralized data (i.e. data in different locations)

TF Privacy : a library with tools to help train models with differential privacy

Mesh TensorFlow: a library to build and train massively large-scale models using parallelism technique

TensorFlow Probability: probably one of the most exciting add-ons in my opinion, TensorFlow Probability is a library for using probabilistic methods in ML models for making predictions dealing with uncertainty and incorporating domain knowledge.

These and many more resources, examples, documentation, and case-studies on TensorFlow can be accessed from the tensorflow.org website.

TensorFlow Extended

One of my favourite add-ons to TensorFlow ecosystem is TensorFlow Extended (TFX). TFX brings the management of the entire machine learning lifecycle to users. It has several component libraries including :

TensorFlow Data Visualization(TFDV) for monitoring and validating ML data at scale.

TensorFlow Transform for preprocessing tasks such as tokenization and format conversions.

TensorFlow Model Analysis (TFMA) to enable developers to calculate and visualize model evaluation metrics.

TensorFlow Serving for serving ML model and support versioning and multiple models support

And as a bonus, it now integrates with open source orchestrators such as AirFlow and KubeFlow.

TensorFlow Lite

Launched last year, TensorFlow Lite (TFLite) is a lightweight solution for on-device inference. According to Google, TFLite is now running on more than 2 billion mobile devices — leading the next generation of ML on device. Running ML in edge device is required for the following reasons:

Fast Interactive Application (by running the ML application on the client side, we can eliminate the overhead of sending the data between server and client)

Data Privacy (by avoiding to send data to the server)

There have been some improvements to TensorFlow Lite’s general usability, model conversion features and performance. For example, by delegating the processing to an edge TPU, they achieve 62x faster inference time at maximum combining with quantization. They also introduce the Coral Dev Board, a single-board computer with a removable system-on-module featuring the Edge TPU, and the Coral USB Accelerator, an USB dongle designed to speed up machine learning inference on existing Raspberry Pi and Linux systems. In addition, they have also presented Sparkfun. Sparkfun is an edge demo board powered by TensorFlow. According to the information provided, Sparkfun can activate a blender or hot-water heater, or do anything your microcontroller can do when it hears a certain word, with nothing but a coin cell battery for power; interesting isn’t it? Even more interesting is that we received the Sparkfun board and the coral USB accelerator as a gift for attending the conference.

TFDevSummit goodies

This kind of gift is always fun because we can try to use what we’ve learned. So I’m going to try all of these later :).

The SparkFun Edge board

TensorFlow.js 1.0

Javascript is one of the most used programming languages and TensorFlow.Js brings ML to JavaScript developers. During the conference they announced the released of TensorFlow.Js. In addition to core components, there are multiple supporting libraries around TensorFlow.js.

Actually, TensorFlow.js project will support various kind of platform such as Electron and React Native so that we can use the same application code in many platforms. Companies like AirBnb and Uber among others are using TensorFlow.js in production environments.

Swift for TensorFlow

Probably one of my favourite announcements last year, Swift for TensorFlow evolved with the release of version 0.2. It’s an incremental improvement; with 0.2, users can see increased usability and try out this novel ML paradigm. In addition, they also launched a new machine learning course using Swift for TensorFlow by fast.ai to make it easier to get started on ML with Swift.

In Codice Ratio

The project is developing a machine transcription system based on TensorFlow to speed up large scale search and knowledge discovery from the Vatican’s historical archives. A custom CNN trained on crowdsourced annotations enables the system to deal with challenging medieval handwriting.

New Courses on TensorFlow and TensorFlow world

Two new new online courses in collaboration respectively with Udacity and Coursera are available to learn TensorFlow.

Finally, a new conference TensorFlow World will be held on Oct 28th-31st, 2019. TensorFlow World conference, organized in collaboration with O’Reilly, will bring engineers, developers, executives, and product managers to discuss their product/service offerings that have been powered by TensorFlow.