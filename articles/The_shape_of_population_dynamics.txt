Despite their fame as fierce killers, reintroducing wolves in the Yellowstone national park in 1995 brought life back to the region. As the wolves chased the deer and moose away from the rivers and valleys, the vegetation began to grow back. Smaller animals like birds and beavers began to settle next to the water, thanks to a much richer habitat. So, as in the case of Romulus and Remus, wolves can be considered as life bearers.

According to the legend, the twin brothers Romulus and Remus were abandoned on the river Tiber to die. Thanks to the help of a she-wolf they managed to survive and founded the city of Rome in 753 BC, Source

Population dynamics can exhibit counter-intuitive behaviour.

Today, the number of endangered species is on the rise. Both identifying and protecting them without jeopardizing the entire eco-system is a real challenge. This is why it is crucial that we derive the right action from early warning signals.

“To every action there is always opposed an equal reaction.” Newton’s 3rd law

Just like Newton wrote an equation explaining the relation between action and reaction, we can rely on mathematical equations to describe population dynamics. This intrinsic modelling approach reveals mechanisms at work inside a population such as the reaction to vanishing resources.

In intrinsic models, noise terms capture environmental uncertainties

To measure repeating patterns in population data, it is natural to seek a method like topological data analysis (TDA) that is stable and universal. Our post explores how topological features can be used to classify aperiodic and stable regimes of population growth.

With just a few topological features, we find that it is possible to boost the performance of a simple baseline model even when significant noise is included.

The approach we follow is inspired by the work of Pereira and de Mello. We provide code to replicate our results using the open-source library Giotto-learn.

Modelling the evolution of a population

The farming industry suffer damage from an infamous beetle — the Tribolium flour beetle. It is so small that hundreds of samples can be found in less than a few grams of flour. When it lacks resources, this beetle relies on cannibalism to restore balance in its population. Thus, they can act as both predator and prey, making them a self contained eco-system.

The flour beetles self regulates its population with cannibalism.

As an attempt to reach a stable population, the beetles self-monitor the ratio of available resources per adult beetle. However, the success of this monitoring operation is not fail proof. Without any external stimulation, the adult beetle population can fluctuate endlessly by order of magnitude without ever reaching a stable population.

First introduced in 1928 by Royal Norton Chapman, the growth model we use to simulate the population dynamics can be found in the 1970’s article by Constantino et al.. We use their difference equation modelling the Tribolium flour beetle population. Our goal is to determine whether the adult beetle population is in its stable or aperiodic state.

Two regimes of adult beetle population as function of time

Two regimes of adult beetle population with increased environmental uncertainty

We show that the TDA approach separates the two cases better than in a baseline model. TDA features are highly predictive to distinguish between stable and aperiodic states in the beetle population. Furthermore they remain predictive even when the conditions in the environment are highly uncertain.

Clustering time series with TDA

The flour beetle is a well studied case in population dynamics exhibiting two distinct behaviours: stable and aperiodic. For many other species, such insight is not given, and finding an adequate model for their evolution is tedious.

However, we can rely on data-science to gain insight on different modes of the population dynamics. We design an agnostic approach to cluster population time series based on similarity measures. The baseline approach is to look at each population time series as a high-dimensional vector and perform the clustering on them.

Our approach relies on TDA to reduce the dimensionality of the problem in a way that compresses and preserves the essential patterns contained in the time series. The pipeline involves the following processing steps:

The idea behind Takens’ embedding is to embed a one-dimensional time series y(t) into a d-dimensional space. In the case of continuous data, we discretize the time series (any method will do), and we apply a sliding window method by selecting d points at τ distance from each other. These values become the coordinates of a vector representing the time window in a d-dimensional space.

A Takens’ embedding on a sinus curve exhibits a loop in the embedding space (here d=2, τ=1)

By progressively sliding the time window over the time series, and repeating this operation, we obtain a new representation of the data in dimension d.

The Takens’ embedding gives us a new perspective revealing otherwise hidden patterns.

This embedding requires tuning parameters such as the embedding dimension d or the time delay τ. Both can either be found experimentally or by minimizing a problem specific loss function.

In giotto-learn, the time delay τ is obtained from the built-in minimization of the time-delayed mutual information.

2. Construct the Vietoris-Rips Complex:

We study the shape and connectivity of this point cloud using the Vietoris-Rips (VR) algorithm. The VR algorithm connects two points when two balls (centered at each point) of increasing radius intersect. Such a procedure lets us observe the merging of connected components, as well as the creation and collapse of a hole (the circle). The following GIF illustrates the concept in a 2D setting:

The Vietoris-Rips algorithm produces a sequence of graphs by progressively connecting the dots

3. Calculate persistence diagrams:

The persistence diagram summarizes the topological information contained in the sequence of graphs produced by the VR algorithm. This summarization consists in a couple (b,d), where b and d denote the radius at which the topological features (component/hole/void) appear and disappear, respectively.

4. Extract features from persistence diagrams:

Persistence diagrams provide qualitative information about the point cloud, but they are not vectors! This is why we cannot use them directly as features. There are many ways to turn persistence diagrams into feature vectors, for example using the distance between two persistence diagrams (which there are many examples of). We use

the mean lifetime of the holes per dimension. the number of holes per dimension. the number of holes that “survive” longer than a given threshold. This threshold is chosen as a fraction of the maximum lifetime of holes (in the dimension). the maximum lifetime of the holes per dimension. the amplitude of the diagram. It acts as the norm of a persistence diagram, as it takes the distance between a persistence diagram and the trivial one (the diagram where all points lie on the line y=x).

5. Perform clustering on features

We apply k-means clustering with k=2 on the resulting TDA features.

Results

TDA features contain performance boosting information not available in the intrinsic model.

The TDA approach, using only the described features, always outperforms the baseline made with 120 features. The homogeneity score of the baseline continuously decreases with the addition of noise to the environment. Once the mean of the standard deviation of the noise reaches 0.5, the baseline approach only finds a single cluster.

Homogeneity score for baseline (blue) and TDA approach (red) as a function of noise

The TDA approach also suffers an early decrease in performance, which can be explained by the increasing similarity between the two cases. When further increasing the noise, the performance recovers, which indicates that looking through the TDA lens, the two cases become distinct again. We can verify this by looking at the persistence diagrams of three sample cases: