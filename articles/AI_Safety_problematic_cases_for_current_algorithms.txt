Artificial Intelligence is currently one of the hottest topics out there, mostly for bad reasons than good. On one hand, we’ve been able to achieve major breakthroughs in technology, putting us one step closer to creating thinking machines with human like perception. On the other, we gave rise to a whole new danger for our society that is not external like a meteorite or a deadly bacteria, but that comes from within humanity itself.

It would be foolish to think that something so powerful and revolutionary can only have a positive impact on our society. Despite the fact that most of the aims within the community are geared towards noble causes, we cannot predict what are the medium to long term effects of inserting AI algorithms in every single part of our lives. Take a look at social media, which is now widely considered as something that can have negative effect on human psyche, all with the purpose of generating more clicks. The truth is that no matter how aware we are of the environment around us, there will always be unwanted side effects from trying to improve peoples’ lives with technology.

However we must also be aware that not everything that is unpredictable needs to be stopped. Risk is part of life, and every single breakthrough in history was in fact a calculated (or not) risk from someone. We cannot simply stop people from creating and innovating. Discoveries will be made and introduced into our lives regardless if we want it or not. The best we can do is to rationalize their impact on us and mitigate the downsides.

This is exactly what we will look into in this article. Towards the end of 2017, DeepMind released a paper called “AI Safety Gridworlds” showcasing a few different scenarios where current reinforcement learning algorithms might fail to comply with the desires of their creators. More specifically we will reproduce th environments of “Absent Supervisor” and “Self-modification” to show that direct application of current algorithms would lead to not only sub-optimal results, but in some situations fatal as well.

The code used for creating the gridworld is built upon the source of my first article: Reinforcement Learning Made Easy (link…