Science is messy. I don’t think people outside the science field appreciate the ratio of failures to successes. In my work, I very often fail to develop an idea to completion. Sometimes the model doesn’t work. Sometimes the idea is just wrong. Sometimes the idea needs to change. Artificial intelligence is more about experimentation and iteration than it is building up strong and clear solutions from paper to production.

The great tragedy of Science — the slaying of a beautiful hypothesis by an ugly fact. — T.H. Huxley

There is a fundamental aspect to science called the null hypothesis. If you have no chance of accepting the null hypothesis when developing your idea, then, simply put, you are not doing science. Many experiments were performed to try and observe the ether, all in vain, as there is no such thing. Similarly, just because you have an idea for some elegant application in artificial intelligence, that doesn’t mean it’s going to work. It just means you have a hypothesis to test.

In the next part of this article I’m going to share with you two negative results I had. Hopefully sharing these bad results will give you a better sense of how science in artificial intelligence can lead to failure, and how to prepare for it, react to it, and push through it.

Unsupervised Learning Machines

The difference between supervised and unsupervised learning is pretty basic: A supervised learning model learns (is trained) to map inputs to outputs, while in unsupervised learning the task is to learn the underlying distribution of the data without labels. The difference in these approaches is not the point of the article, and so keep in mind that unsupervised learning is about learning how things work, rather than learning what box to put them in. Given some creative license, I would say that the goal in unsupervised learning is the act of learning itself; to learn about the dataset of stuff the model is shown.

Introduction to Failure (Part 1): CAE for Face Embeddings

In some recent research work, I have been trying to build a Convolutional AutoEncoder (CAE) to learn embeddings for faces. In simple terms, I am trying to find meaningful small vectors to represent images of faces. Why? Here is a motivating recent example of using face embeddings to generate content:

My original motivation was the DCGAN paper, a predecessor of the work described above. See figures 7 and 8 on pages 10 and 11 of this paper (DCGAN) to get an idea for why face embedding is so cool. Can a CAE do the same thing as DCGAN?

Below is a video from 2017 that shows the basics of the idea with a DNN (dense) autoencoder and PCA, motivating me to believe that a CAE should work (2018 update here):

Last year I published a paper with some colleagues on CAE for processing multi-microphone audio signals, and so I have enough of a background to try out ideas. Never mind how the CAE model works, it struck me that a picture is worth a thousand words, and images are a great medium for showing what a neural network is learning. So why not use a CAE instead of a GAN to learn face embeddings? A CAE is supposed to reconstruct an image back into the original after compressing it down to some bottleneck size. My hypothesis was that this would “work” for me on faces images. I grabbed a pretty good faces images dataset and started programming a CAE.

Around this time, I was reading a related paper called “Comparison of Unsupervised Modulation Filter Learning Methods for ASR” and they mention, a few types of models for unsupervised learning (GAN, CAE, and other networks). The idea is that several types of model can be used to learn unsupervised about the structure of data. This gave me some confidence that a CAE could do what GANs are doing in terms if semantic image embedding.

Let’s see what that learning process looks like during my first day of model training after the initial model development. The first row in the video below is the input face images and the second row in the output (for test data, not training data) that is supposed to look the same:

I could see that the model learned some stuff, and was getting better over time. Notice that the output was saturated or at cutoff on various channels: white is 3 channel saturation, yellow is 2 channel saturation (RED=255, GREEN=255, BLUE=0), black is all 0s, and so forth. There are no middle-ground pixel values like 123 or 65, just 0s and 255s. The loss was going down over time, but was delivering diminishing returns at about 0.5 loss. And so I experimented with longer training times, batch normalization, tanh activation instead of sigmoid, different sized networks and bottlenecks, different sizes of images, and LOTS of other approaches. Here were the results for day 2:

And for day 3:

At this point, I was ready to rip my hair out and throw my computer out the window. I was following the same approaches that worked for GAN papers like batch normalization, and failing miserably. I was running experiments in parallel, and I started to rope in colleagues to join my failing quest. This led to an aha moment. Perhaps my idea was a bit off. Let’s take a step back. Why not use a VAE or a GAN instead of a CAE?

Changing My Idea: How About a VAE or Something Else?

I had to face the fact that my CAE approach and basically all of my work to this point was not going to work, and I didn’t know why. I had some ideas, but not proof of what was going wrong. Throwing away several days of work is not a good feeling, but I had to embrace the null hypothesis, that my CAE was not good enough at reconstructing face images to be used for semantic embedding operations. GANs are popular for this task because they DO work (e.g. DCGAN), and I just set a few days of my time on fire to try and do something cool that ultimately did not work. Maybe a Variational AutoEncoder (VAE) would work better? That’s what the literature was indicating…

At this lowest point, I heard back from Mary Kate MacPherson. Not only did she get a CAE model to work, her CAE code looks almost exactly like my code. This is the point where I look back and think to myself that there really are a LOT of ways to not make a light bulb. Here is a view of her results after a couple hours of training: