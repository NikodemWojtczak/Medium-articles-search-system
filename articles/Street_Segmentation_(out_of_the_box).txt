Street Segmentation (out of the box)

If you quickly need a model for Street Segmentation, this is the way to do it. shafu.eth · Follow 4 min read · Jul 6, 2019 -- 1 Listen Share

The street segmentation task is something that is very important for many different people in the industry and research that can be quite challenging. It can be very hard to design and train your own network architecture from the ground up with your own dataset. Therefore I want to show you here the best “out of the box” solutions for Street Segmentations and the available training sets.

What is Street Segmentation?

If you have an image and you want to know which pixels of the image are street and which are not, you have a Street Segmentation task.

More formally:

For a given high-resolution image, categorize each pixel into a set of semantic labels.

Those labels could be anything like a street sign, sidewalk, tree, person, car and of course street.

Available training data

If you want to train your own algorithm but you don’t have training data (HINT: Look at the licenses of the training data before using them) there are available datasets you can use:

Cityscapes: This dataset is created by the German car company Daimler. There are 5k images where the segmentation is nearly perfect and another 20k images with good segmentation masks. This dataset is unfortunately not available for you to download directly. You have to sign up on their website and request access. I would say it’s worth it though because this dataset is perfect for street segmentation.

CamVid

ADE20k: This data is provided by MIT. It wasn’t created specifically for street segmentation, but there some images with street in the dataset.

Pre-trained models

If you don’t want to train your own architecture you can simply use pre-trained models. The best I found is the TensorFlow DeepLab Model Zoo networks. You can find here models that are trained on the Cityscapes or the ADE20k dataset. The one I found to work very good for me is the Xception71 model trained on Cityscapes. You can download the model here.

Run pre-trained model

Load the model:

The load graph method takes as input the full path to your .pb file that you downloaded before. It returns a Tensorflow graph that we will use for inference.

2. Run the model:

We will run the model on one image with the segment method. The method takes as input the graph we created with the load_graph method and a full path to your image.

Then we have to initialize the input and output nodes of the model. After that we create a session load the image, resize it. You can resize your image to any size (I use this size to make inference faster). After that, we run the model and we get the prediction. The prediction is the segmentation mask.

You can’t open this segmentation mask just yet, because it is not a RBG image. It just assigns a label index for each pixel. So you have a number between 1–20 for each class. You will need to parse this prediction to view it as an image.

3. Parse the prediction:

We will assign each class a specific color. To create some RGB colors I use the following method.

This will create n evenly spaced RGB colors for us. Don’t ask me how this function used ;) I found it here. A big thanks go to Reed Oei for this function. It saved me some time copying and pasting random RGB values. Now we need to parse the prediction.

It takes as input the prediction that we created with the segment method. We then get all unique values from the prediction and create an empty numpy array with the same dimensions of the prediction but with 3 channels. Remember, we create an RGB image here. Then we get the RGB colors. Now we iterate over every unique value and get the indexes where the prediction matches this value. After that we assign that value an RGB code and fill the empty array for all the indexes we found with this color and repeat that for all unique values.

I know that you are confused right now. I could have written a function that would be much easier to read but would be very very slow. The numpy operations make this function super fast.

At the end, we save the array as a uint8 array and then create a PIL.Image object that we can open or save.

The whole code as one script:

Results

If you want to see how this model could perform, check this awesome youtube video out:

Conclusion

I hope this tutorial was helpful and understandable. I think street segmentation and the semantic segmentation task, in general, is a very cool field and I hope you could learn something here. If you have any questions, leave them in the comments below.

Thank you for reading and keep up the learning!

If you want more and stay up to date you can find me here: