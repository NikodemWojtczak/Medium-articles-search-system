Implementing the regression strategy using Python, pandas and statsmodels

Import all the required packages.

import pandas as pd from patsy import dmatrices from collections import OrderedDict import itertools import statsmodels.formula.api as smf import sys import matplotlib.pyplot as plt

Read the data set into a pandas data frame.

df = pd.read_csv('boston_daily_temps_1978_2019.csv', header=0, infer_datetime_format=True, parse_dates=[0], index_col=[0])

The data set contains daily average temperatures. We want monthly averages. So let’s roll up the data to a month level. This turns out to be a simple thing to do using pandas.

df_resampled = df.resample('M').mean()

We are about to add lagged variable columns into the data set. Let’s create a copy of the data set so that we don’t disturb the original data set.

df_lagged = df_resampled.copy()

Add 12 columns, each one containing a time-lagged version of TAVG.

for i in range(1, 13, 1):

df_lagged['TAVG_LAG_' + str(i)] = df_lagged['TAVG'].shift(i)

Print out the first 15 rows of the lagged variables data set.

print(df_lagged.head(15))

This prints out the following output:

The data set containing 12 lagged variables (Image by Author)

The first 12 rows contain NaNs introduced by the shift function. Let’s remove these 12 rows.

for i in range(0, 12, 1):

df_lagged = df_lagged.drop(df_lagged.index[0])

Print out the first few rows just to confirm that the NaNs have been removed.

print(df_lagged.head())

Before we do any more peeking and poking into the data, we will put aside 20% of the data set for testing the optimal model.

split_index = round(len(df_lagged)*0.8) split_date = df_lagged.index[split_index] df_train = df_lagged.loc[df_lagged.index <= split_date].copy() df_test = df_lagged.loc[df_lagged.index > split_date].copy()

Now let’s create all possible combinations of lagged values. For this, we’ll create a dictionary in which the keys contain different combinations of the lag numbers 1 through 12.

lag_combinations = OrderedDict() l = list(range(1,13,1))



for i in range(1, 13, 1):

for combination in itertools.combinations(l, i):

lag_combinations[combination] = 0.0

Next, we will iterate over all the generated combinations. For each lag combination, we’ll build the model’s expression using the patsy syntax. Next we’ll build the linear regression model for that lag combination of variables, we’ll train the model on the training data set, we’ll ask statsmodels to give us the AIC score for the model, and we’ll make a note of the AIC score and the current ‘best model’ if the current score is less than the minimum value seen so far. We’ll do all of this in the following piece of code:

#Current minimum AIC score

min_aic = sys.float_info.max #Model expression for the best model seen so far

best_expr = '' #OLSResults objects for the best model seen so far

best_olsr_model_results = None



expr_prefix = 'TAVG ~ ' #Run through each lag combination

for combination in lag_combinations:

expr = expr_prefix



i = 1 #Build the model's expression in patsy notation, for e.g. 'TAVG ~ TAVG_LAG_1 + TAVG_LAG_2' represents a model containing two lag variables and TAVG_LAG_1 and TAVG_LAG_2 plus the intercept for lag_num in combination:

if i < len(combination):

expr = expr + 'TAVG_LAG_' + str(lag_num) + ' + '

else:

expr = expr + 'TAVG_LAG_' + str(lag_num)



i += 1



print('Building OLSR model for expr: ' + expr)



#Given a model expression, patsy makes it easy to carve out the X,y matrices from the data set. We will use X_test, y_test later for testing the model. y_test, X_test = dmatrices(expr, df_test, return_type='dataframe')



#Build and fit the OLSR model using statsmodels

olsr_results = smf.ols(expr, df_train).fit()



#Store away the model's AIC score

lag_combinations[combination] = olsr_results.aic print('AIC='+str(lag_combinations[combination])) #If the model's AIC score is less than the current minimum score, update the current minimum AIC score and the current best model

if olsr_results.aic < min_aic:

min_aic = olsr_results.aic

best_expr = expr

best_olsr_model_results = olsr_results

Finally, let’s print out the summary of the best OLSR model as per our evaluation criterion. This is the model with the lowest AIC score.

print(best_olsr_model_results.summary())

This prints out the following output. I have highlighted a few interesting areas in the output:

Model summary generated by statsmodels OLSResults.summary() (Image by Author)

Let’s inspect the highlighted sections.

Choice of model parameters

Our AIC score based model evaluation strategy has identified a model with the following parameters:

Model parameters and their regression coefficients (Image by Author)

The other lags, 3, 4, 7, 8, 9 have been determined to not be significant enough to jointly explain the variance of the dependent variable TAVG. For example, we see that TAVG_LAG_7 is not present in the optimal model even though from the scatter plots we saw earlier, there seemed to be a good amount of correlation between the response variable TAVG and TAVG_LAG_7. The reason for the omission might be that most of the information in TAVG_LAG_7 may have been captured by TAVG_LAG_6, and we can see that TAVG_LAG_6 is included in the optimal model.

Statistical significance of model parameters (the t-test)

The second thing to note is that all parameters of the optimal model, except for TAVG_LAG_10, are individually statistically significant at a 95% confidence level on the two-tailed t-test. The reported p-value for their ‘t’ score is smaller than 0.025 which is the threshold p value at a 95% confidence level on the 2-tailed test.

The t value and the p-value of the model parameters (Image by Author)

Joint significance of model parameters (the F-test)

The third thing to note is that all parameters of the model are jointly significant in explaining the variance in the response variable TAVG.

This can be seen from the F-statistic 1458. It’s p value is 1.15e-272 at a 95% confidence level. This probability value is so incredibly tiny that you don’t even need to look up the F-distribution table to verify that the F-statistic is significant. The model is definitely much better at explaining the variance in TAVG than an intercept-only model.

F-statistic and its p-value. All mdoel parameters are jointly significant (Image by Author)

To know more about how to interpret the F-statistic, please refer to my article on the F-test.

The AIC score and the Maximized Log-Likelihood of the fitted model

Finally, let’s take a look at the AIC score of 1990.0 reported by statsmodels, and the maximized log-likelihood of -986.86.

Maximized Log-likelihood and the AIC score (Image by Author)

We can see that the model contains 8 parameters (7 time-lagged variables + intercept). So as per the formula for the AIC score:

AIC score = 2*number of parameters —2* maximized log likelihood

= 2*8 + 2*986.86 = 1989.72, rounded to 1990. 0

Which is exactly the value reported by statmodels.