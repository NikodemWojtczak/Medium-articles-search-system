In 1949, Warren Weaver, a researcher at Rockefeller Foundation, presented a set of proposals for machine based translations which were based on information theory and successes in code breaking during the Second World War.

After few years, the machine translation research began in earnest in many US universities. As described by Hutchins Report, on January 7th 1954, the Georgetown-IBM experiment started, the IBM 701 computer automatically translated 60 Russian sentences into English for the first time in history. This was the first public demonstration of a machine translation system and it garnered much media and public interest.

The ALPAC Report stated that machines cannot compete with the human translation quality and suggested that the funding for Machine Translation should be stopped. But several researchers kept on studying how the machine can be used to create automated language translations. Most of these researches concentrated on limited language pairs with limited input and rule based engines. By the 1980s, a significant number of machine translation engines which relied on mainframe technologies were in use such as SYSTRAN, Logos etc.

Statistical Machine Translation

Brown et. al (1990) proposed the use of statistical methods in Machine Translations. They proposed a translation process where the source text is partitioned into a set of fixed locations, then the glossary is used to select the set of fixed locations to create a sequence, and finally words in target fixed locations are rearranged to form a target sentence. They successfully developed the statistical techniques for automatic glossary creation and arrangement of target word sequences but failed to provide examples for translated sentences.

Brown et. al (1993) described a series of five statistical models for the translation process and gave algorithms for estimating the parameters of these models given a set of bilingual pairs of sentences. These models were later considered as the IBM alignment models. They defined the concept of word-by-word alignment between the pair of bilingual sentences. Their algorithm assigned a probability to each of these word-by-word alignments for any given pair of sentences. Though their research was confined to smaller English and French translations but it was a considerable improvement to the alignment of word-by-word relationships in the pair of sentences.

Vogel et. al (1996) described a new model for word alignment in the Statistical Machine Translation using first-order Hidden Markov Model as it solved the time alignment problem for speech recognition. The main idea behind the model was to make the word-by-word alignment probabilities depend on the alignment positions rather than the absolute positions. The HMM-based model produced translation probabilities on par with the mixture alignment model and position alignments were much smoother in HMM-based model.

Och et. al (1999) described a method to determine bilingual word classes to be used in Statistical Machine Translation. They developed an optimisation criterion based on the maximum likelihood approach and further described a clustering algorithm. The results of their experiments showed that the usage of bilingual word classes improved the statistical machine translations significantly.

A syntax-based statistical translation model was proposed by Yamada et. al (2001) . Their model transformed a source-language parse tree into a target-language string by applying stochastic operations at each node. Those operations captured the linguistic differences such as word order and case marking. The model produced word alignments which were better those produced by IBM Model 5 .

A novel phrase-based translation model and decoding algorithm was proposed by Koehn et. al(2003) which enabled them to evaluate and compare several previously proposed phrase-based translation models. They designed an uniform framework to compare different other translation models. The model proposed by Koehn et. al(2003) was based on the noisy channel model Brown et. al(1993) and they used the Bayes rule to reformulate the translation probability for translating a foreign sentence in French into English.

Chiang et. al(2005) presented a phrase-based machine translation model that used hierarchical phrases – phrases that contained subphrases.They proposed the use of hierarchical phrases which consisted of both words and sub-phrases to address this problem. Their model was based on a weighted synchronous Context Free Grammar. The model built partial translations using the hierarchical phrases and then combined them serially in a standard phrase-based model. Instead of using the traditional noisy-channel approach , they used a more general log-linear model.

Neural Machine Translation

In 2013, a new end-to-end encoder-decoder structure for machine translation was proposed by Kalchbrenner & Blunsom(2013). They introduced a class of probabilistic continuous translation models called Recurrent Continuous Translation Models which were purely based on continuous representations for words, phrases and sentences and did not rely on alignments or phrasal translation units.

Sutskever et al.(2014) proposed the use of Deep Neural Networks in Sequence to Sequence learning for Machine Translations. Their method used a multi-layered Long Short-Term Memory (LSTM) to map the input sequence to a vector of a fixed dimensions, and then used another deep LSTM to decode the target sequence from the vector. Their results showed that Neural Machine Translation system having large deep LSTM with a limited vocabulary can outperform a standard SMT-based system.

Cho et. al (2014) proposed a new neural network model with two recurrent neural networks (RNN) as Encoder and Decoder. One RNN encoded a sequence of symbols into a fixed length vector representation, while the other decoded the representation into another sequence of symbols. Their results showed that RNN Encoder–Decoder were able to capture both semantic and syntactic structures of the phrases.

Bahdanau et. al (2014) proposed a method which allowed a model to automatically soft-search for parts of a source sentence that are relevant in predicting a target word,without having to form these parts as a hard segment explicitly. With this approach, they achieved e a translation performance comparable to the existing state-of-the-art phrase-based system on the task of English-to-French translation.

Luong et. al (2015) proposed two effective classes of attentional mechanism, a global approach which always attends to all source words and a local one that only looks at a subset of source words at a time.Their ensemble model using different attention architectures established a new state-of-the-art result in the WMT'15 English to German translation task with 25.9 BLEU points.

Jozefowicz et. al (2016) experimented with different neural network models on different sizes of corpora, their experiments showed that RNNs can be trained on large amounts of data, and they outperform competing models including carefully tuned N-grams. Their experiments showed that a large, regularized LSTM LM, with projection layers and trained with an approximation to the true Softmax with importance sampling performed much better than N-grams.

In the Findings of First Conference on Machine Translation (WMT'16), the neural machine translation systems that participated in the WMT evaluation outperformed phrase-based statistical machine translation system by up to 3 BLEU score (Bojar et. al 2016).

Philip Koehn wrote, "Neural Machine Translation (NMT) is an exciting and promising new approach to Machine Translation. However, while the technology is promising we still have some way to go to commercial implementations that can rival Rule Based Machine Translation (RBMT) and Statistical Machine Translation (SMT) in all use cases. Some recent claims by industry players to suggest that near human quality is right around the corner for all of us, might be a bit of an over-simplification.". He argued that even if the Neural Machine Translation systems produce superior quality results, its very difficult to implement such systems at an industrial scale as it would require huge investment in infrastructure for processing the translations.

Google's Neural Machine Translation

Wu et al (2016) proposed a model which follows the common sequence-to-sequence learning framework Sutskever et al.(2014) with attention Bahdanau et. al (2014). The model has three components: an encoder network, a decoder network and an attention network. The encoder network converts a source sentence into a list of vectors, one vector per input symbol. When this list of vectors is passed to decoder network it produces one symbol at a time until it encounters the special end-of-sentence symbol (EOS). The encoder and decoder are connected through an attention module which allows the decoder to focus on different regions of the source sentence during the course of decoding.

Wu et al (2016) description of the architecture is as follows. On the left is the encoder network, on the right is the decoder network, in the middle is the attention module. The bottom encoder layer is bi-directional: the pink nodes gather information from left to right while the green nodes gather information from right to left. The other layers of the encoder are uni-directional. Residual connections start from the layer third from the bottom in the encoder and decoder. The model is partitioned into multiple GPUs to speed up training. In their setup, they have 8 encoder LSTM layers (1 bi-directional layer and 7 uni-directional layers), and 8 decoder layers. With this setting, one model replica is partitioned 8-ways and is placed on 8 different GPUs typically belonging to one host machine. During training, the bottom bi-directional encoder layers compute in parallel first. Once both finish, the uni-directional encoder layers start computing, each on a separate GPU. To retain as much parallelism as possible during running the decoder layers, they used the bottom decoder layer output only for obtaining recurrent attention context,which is sent directly to all the remaining decoder layers. The softmax layer is also partitioned and placed on multiple GPUs. Depending on the output vocabulary size they either have them run on the same GPUs as the encoder and decoder networks, or have them run on a separate set of dedicated GPUs.

Their decoder network is implemented as an amalgamation of an RNN network and a softmax Layer. The decoder RNN network creates a hidden state for the next symbol to be predicted, which then goes through the softmax layer to generate a probability distribution over candidate output symbols. In their experiments the authors found out that Neural Machine Translation systems must have deep RNNs for encoder and decoder networks to achieve good accuracy, they need to capture the minute irregularities in the source and target languages. The Attention Model they implemented in their research is similar to Bahdanau et. al (2014).

Wu et al (2016) acknowledged the fact that simply tacking up more Layers of LSTM makes the network slower and difficult to train, likely due to exploding and vanishing gradient problems.They introduced residual connections among the LSTM layers in a stack. Residual Connection greatly improved the gradient flow in the backward pass, which allowed them to train their encoder and decoder networks with 8 LSTM layers. They used the bi-directional connections for the bottom encoder layer while keeping other layer uni-directional to allow maximum parallelisation during computation.

Wu et al (2016) used two publicly available corpora WMT’14 English-to-French and English-to-German as benchmarks for their Neural Machine Translation systems. In addition to these publicly available corpora they used Google’s translation production corpora which is much bigger than the WMT corpora for a given language pair. The WMT En->Fr contains 36M sentence pairs while the En->De contains 5M sentence pairs. They evaluated their models by carrying out side by side Human evaluations along with standard BLEU score metric. The side by side scores ranged from 0 to 6, with a score of 0 meaning “completely nonsense translation”, and a score of 6 meaning “perfect translation: the meaning of the translation is completely consistent with the source, and the grammar is correct”. They trained the models using the system they implemented in TensorFlow. They used word-based, character-based, mixed-character-based and several wordpiece models with different vocabulary sizes for the experiments. Table summarizes the results they achieved on WMT En ->Fr dataset. Their best model, WPM-32K achieved a BLEU score of 38.95. The WMT En ->De was much more difficult than the En-> Fr due to the less size of training data and German is a more morphologically rich language which needs vocabulary for word models. Their best model WPM-32K achieved a BLEU score of 24.61.

They further used RL training to fine-tune the sentence BLEU score after normal maximum-likelihood training.They ensembled 8 RL-refined models and obtained a state-of-the-art result of 41.6 BLEU points on the WMT En->Fr dataset. They obtained a state-of-the-art result of 26.30 BLEU points on the WMT En->De dataset. The four translations were: 1) the best phrase-based translation downloaded from statmt website, 2) an ensemble of 8 ML-trained models, 3) an ensemble of 8 ML-trained and then RL-refined models, and 4) reference human translation directly obtained from test data. The results are showed in Table. The results clearly showed that though RL refinement can achieve better BLEU scores, but it barely improved the human impression of the translation quality.

Google’s NMT is the current state of art in Machine Translation.

For Spanish translation or Traducción a Español by www.ibidemgroup.com click here.