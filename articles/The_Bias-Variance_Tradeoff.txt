In this post, we will explain the bias-variance tradeoff, a fundamental concept in Machine Learning, and show what it means in practice. We will show that the mean squared error of an unseen (test) point is a result of two competing forces (bias/variance) and the inherent noise in the problem itself.

Motivation

We often see in machine learning textbooks the image below describing the generalization (test) error and its connection to model complexity. The generalization (test) error, which is the error in unseen data, can be decomposed in bias error (error from wrong model assumptions), variance (error from sensitivity to small fluctuations in training data) and irreducible error (inherent noise in the problem itself).

High bias usually stems from oversimplifying model assumptions, while high variance from overcomplex assumptions. Irreducible error, as the name suggests, is irrelevant of the underlying model and has to do with the inherent noise in the problem. This noise can represent noise coming from data quality (e.g., inaccuracies in collection or reporting of data), from only approximate knowledge of the true function describing the real-life problem, from non-deterministic behavior of the underlying phenomenon and, in general, any type of noise that cannot be easily defined. When our model suffers from high bias, the average response of the model is far from the true value and we call this underfitting. When our model suffers from high variance, this is usually a result of its inability to generalize well beyond the training data and we call this overfitting. Our goal is to build a model that achieves a balance between bias and variance so that the combined error of these two competing forces is minimum*. This is the middle zone in the above plot!

* Usually, traditional machine algorithms (e.g., regression algorithms, gradient boosting trees, SVMs, etc) suffer from the bias-variance tradeoff as model complexity increases. Recent advances in deep learning though have questioned the established notion of increased variance with model complexity as long as there’s abundance of training data.

Problem definition

Let’s start by defining some key concepts. We assume we have independent variables x that affect the value of a dependent variable y via a deterministic or non-deterministic relationship. We say non-deterministic because y’s value can also be affected by noise that cannot be modeled explicitly. Let’s denote the dependence of y on x via function f, that essentially represents the true underlying relationship between x and y. In real situations, it is of course very hard — if not impossible — to know this relationship, but we will assume that f is fixed, even when it is unknown. In that case, y which is the result of x and random noise, is given by the formula:

Noise is modeled by random variable ϵ with zero mean and variance σϵ². The magnitude of variance represents the level of uncertainty about the underlying phenomenon. The larger our uncertainty is, the bigger the value of σϵ². Mathematically, ϵ has the following properties:

Now, when we try to model the underlying real-life problem, what this means actually is that we try to find a function f̂ such that it is as close to the true (yet unknown to us) function f. Function f̂ can take the form of coefficients in the regression case, support vectors and dual coefficients in the case of Support Vector Machines (SVMs) and it is learned from training data. The closer the underlying distribution generating training data is to the underlying distribution generating test (unseen) data, the better the model represented by function f̂ will generalize to unseen data. Function f̂ is learned by minimizing a loss function whose goal is to bring predictions of training data as close as possible to their observed values: y ≈ f̂(x).

Mean squared error (MSE, for abbreviation) is the average squared difference of a prediction f̂(x) from its true value y. It is defined as:

Bias is defined as the difference of the average value of prediction (over different realizations of training data) to the true underlying function f(x) for a given unseen (test) point x.

Let’s spend some time to explain what we mean by “different realizations of training data”. Assume we want to monitor the relationship between family income level and house sale prices in a certain neighborhood. If we had access to data from every household, we would be able to train a very accurate model. But because obtaining data can be costly, time-consuming or subject to privacy concerns, most of the times we do not have access to all data of the underlying population. A realization means that we have access to only a portion of the underlying data as our training data. This realization can be unrepresentative of the underlying population (for example, if we poll only houses where a household has certain educational level) or representative (if it is done without racial, educational, age or other types of biases). So, when we say that expectation 𝔼[f̂(x)] is over different realizations of training data, this can be thought of as if we had the opportunity to poll a sample out of the underlying population, train our model f̂ on this sample, compute f̂(x) and repeat this multiple times (with a different training sample each time). The average of predictions will represent 𝔼[f̂(x)]. Here, f̂(x) changes even though x is fixed, simply because f̂ depends on training data. So, f̂ will be different for different realizations of training data. In more mathematical terms, f̂ is a random variable affected by the randomness in which we obtain training data.

Variance is defined as the mean squared deviation of f̂(x) from its expected value 𝔼[f̂(x)] over different realizations of training data.

The formula that connects test MSE to bias, variance and irreducible error is:

The first expectation in term 𝔼[𝔼[(y −f̂(x))²]] is over the distribution of unseen (test) points x, while the second over the distribution of training data and random variable ϵ. Because f̂ depends on training data we can also say that the second expectation is over over f̂, ϵ. If we were to write the above formula more explicitly, it would be:

but we will skip the expectation identifiers for simplicity. All three terms on the right hand side are non-negative and irreducible error is not affected by model choice. This means that test MSE cannot go below σϵ². We will now derive the formula for a given test point x. Since it will hold for a given test point x, it will hold for any distribution of unseen test points.

Proof of bias-variance decomposition

As a reminder, we assume x is an unseen (test) point, f is the underlying true function (dictating the relationship between x and y), which is unknown but fixed and ϵ represents the inherent noise in the problem. Test MSE, 𝔼[(y −f̂(x))²] is over the different realizations of training data and random variable ϵ:

(1) is because y = f(x) + ϵ, (2) because of square expansion, linear property of expectation and independence of random variables ϵ and f̂. Remember that when two random variables are independent, the expectation of their product is equal to the product of their expectations. In Eq. (3), we see how test MSE decomposes to irreducible error σϵ² and 𝔼[(f(x) −f̂(x))²]. Let’s see now how this latter term can be further analyzed.

In Eq. (4) we subtract and add by 𝔼[f̂(x)] and in Eq. (5) we expand the terms inside the square. Bias 𝔼[f̂(x)] − f(x) is just a constant since we subtract f(x) (a constant) from 𝔼[f̂(x)] which is also a constant. Therefore, applying expectation to squared bias, (𝔼[f̂(x)] − f(x))² does not have any effect. In other words, 𝔼[(𝔼[f̂(x)] − f(x))²] = (𝔼[f̂(x)] − f(x))². In Eq. (6), we are able to pull f(x) −𝔼[f̂(x)] out of the expectation, because as we mentioned it is just a constant. Lastly, (7) holds because of linearity of expectation. Therefore, we see in (8) that 𝔼[(f(x) −f̂(x))²] is the sum of squared bias and variance. When we combine Eqs. (3) and (8), we end up with:

This is for a given test point x, but we usually have a set of test points and this converts to the formula we presented in the previous section.

(Expectation 𝔼 in the right hand side is over the distribution of test data.)

Showing bias-variance tradeoff in practice

After we derived the bias-variance decomposition formula, we will show what does it mean in practice. Assume, the underlying true function f that dictates the relationship between x and y is:

and the noise is modeled by a Gaussian with zero mean and standard deviation 1, ϵ ~𝒩(0, 1). As a reminder, y = f(x) + ϵ. If we randomly generate 1,000 points from this process, we get the following plot.

Blue dots represent (x, y) pairs and red line is the underlying true function f(x). Red dot is the unseen (test) point we want to predict. We see that f follows a non-linear pattern due to the addition of square root and cosine in the function’s definition. For our purposes, these 1,000 points represent the whole underlying population. Here is the code to reproduce this plot.

We will model the problem with polynomial regressions of varying degrees of complexity. As a reminder, in polynomial regression we try to fit the following non-linear relationship between x and y.

In other words, we try to approximate y with f̂(x) as described in Eq. (9). We will not go into details how model parameters w₀, w₁, …, wd are learned as it is beyond the scope of this article, but let’s assume they are evaluated by minimizing a loss function that tries to bring f̂(x) as close to y as possible.

Now, let’s assume we could only use 20 points (out of the 1,000) to train our polynomial regression model and we consider four different regression models, one with degree d=1 (simple line), one with d=2, d=3 and d=5. If we randomly sample 20 points from the underlying population and we repeat this experiment 6 times, this is a possible outcome we get.

Blue dots represent the 20 training data points for a specific realization (experiment). The red line is the underlying (unknown to us) true function f and the other lines represent the fitting of the four different models to different realizations of training data. The green, purple, cyan, orange dots represent the prediction f̂(x) of test (unseen) point x under each model. As we see, there’s less variation in lines with smaller degrees of complexity. Take for instance d=1 (simple line). The slope of the line does not change all that much between different experiments. On other other hand, a more complex model (d=5) is much more sensitive to small fluctuations in the training data. See for example the difference in the orange line (d=5) between experiment 1 and 6 and how this affects prediction f̂(x). This is the variance problem we mentioned in previous sections. A simplistic model is very robust to changes in training data, but a more complex is not. On other hand, the deviation of f̂(x) from f(x) on average (the bias), is larger for more simplistic models, since our assumptions are not as representative of the underlying true relationship f. Here is the code for the above plots.

Now, assume we simulate 10,000 different experiments by randomly sampling each time 20 points from the underlying population to serve as our training data. On each experiment we learn a different f̂ tied to that experiment’s training data. If for a given unseen test point x, we evaluate f̂(x) for each experiment, we will gather 10,000 values for f̂(x). We do this for linear (d=1) and quadratic (d=2) regression models. If we hist these 10,000 values, we obtain the following plots. (Note that in the code and plots, test point is denoted with x_test and training data with x_train. In other words, even though we denote the test point in this article by x, in the code we represent it with variable x_test for avoidance of confusion).

As we see, the mean of f̂(x), 𝔼[f̂(x)], represented by the black line is further from true f(x) (red line) for the linear regression model than it is for the quadratic one (purple hist). This is the bias, in other words, the deviation from the true model when our model assumptions are overly simplistic. On the other hand, the variance of f̂(x), var(f̂(x)) is larger on the quadratic model than the linear one as we see by the larger spread of the bottom (purple) histogram. This is the variance problem, in other words, the larger dependence of f̂(x) on small fluctuations of the training data. Here is the code that reproduces the histogram plots.

Now let’s consider 1,000 test points and compute the average test MSE (over these points). We also compute the average squared bias (over these 1,000 test points) and average variance. If we do this for five models, from degree d=0 (horizontal line) all the way to degree d=4, we get the following plot.

If we add the yellow (squared bias), blue (variance) and red (irreducible error) lines together, we obtain the green line (test error). This is our familiar bias-variance formula!

Black line represents the training MSE, which reduces with model complexity, as more complex models tend to fit training data better. In this particular example, we see that the best model for the underlying problem is a quadratic one (d=2), since it achieves minimum test error. The code for the above plot is posted below.

If you are interested to learn more about the bias-variance problem, here is a very helpful tutorial by Andrew Ng.

Conclusion

In this article, we presented the bias-variance problem. We proceeded with its mathematical derivation and showed with an example what the bias-variance really means in practice. We demonstrated that model choice has to battle two competing forces: bias and variance. A good model should strike a balance between the two but we can never achieve zero test error due to the presence of irreducible error. Our model should not be overly simplistic, but not too complex either so that it can generalize well to previously unseen data.