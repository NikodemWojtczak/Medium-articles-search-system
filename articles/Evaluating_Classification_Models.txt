Evaluating Classification Models

Authors: Ishaan Dey, Evan Heitman, & Jagerynn T. Verano

Introduction to Classification

A doctor wants to know if his patient has a disease. A credit card company is interested in determining if a certain transaction is a fraud. A graduate school candidate is interested if whether or not it’s likely that she gets accepted into her program. Many applied models are interested in predicting the outcome of a binary event, which is any event that can be answered by a simple yes or no question. This is called a binary classification problem, and is distinct from multi-class classification, where we would be interested in predicting which disease an individual would have, or which product a customer would purchase from a selection.

Overview

Regression models will often report familiar metrics, such as R2, to show goodness-of-fit, or how well the model can adhere to the data. With discrete outcomes, we cannot apply the same formulas, so in this post, we will examine how to evaluate a classifier model’s performance, by breaking down the types of error a model can mistake and quantitative measures that can summarize a model’s ability to perform as we expect it to.

Throughout this post, we use a credit card transaction dataset, with targets labelling a fraudulent transaction (a binary outcome, with 1 indicating fraud). Given the low occurrence of fraud, the dataset was under-sampled to create a new distribution of 90:10 non-fraud to fraud observations. That data was further split into a 70:30 train to test split. We fitted a logistic regression model, and used a threshold of 0.5 to predict values as a fraud. You can follow along using the interactive python notebook linked below.

The Basics: Confusion Matrix

Confusion Matrix from a Binary Classification Model

For any dataset containing binary outcomes, we can label all observations with a 1 (indicating the occurrence of an event) or 0 (the absence of an event). We can fit a model to the feature variables and make a prediction for each observation given the set of feature variables. Values…