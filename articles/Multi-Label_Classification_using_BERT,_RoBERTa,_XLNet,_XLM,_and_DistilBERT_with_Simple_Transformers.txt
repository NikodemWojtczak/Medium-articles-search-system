Preface

The Simple Transformers library is built on top of the excellent Transformers library by Hugging Face. You guys are incredible!

Simple Transformers now supports:

There’s plenty more in the pipeline.

Introduction

Transformer models and Transfer Learning methods continue to propel the field of Natural Language Processing forward at a tremendous pace. However, state-of-the-art performance too often comes at the price of tons of (complex) code.

Simple Transformers avoids all the complexity and lets you get down to what matters, training and using Transformer models. Bypass all the complicated setups, boilerplates, and other general unpleasantness to initialize a model in one line, train in the next, and evaluate with the third.

This guide shows how you can use Simple Transformers to perform Multilabel Classification. In Multilabel Classification, each sample can have any combination (none, one, some, or all) of labels from a given set of labels.

All source code is available on the Github Repo. If you have any issues or questions, that’s the place to resolve them. Please do check it out!

Installation