10 Lessons I Learned Training GANs for one Year

Introduction

A year ago I decided to begin my journey into the world of Generative Adversarial Networks, or GANs. I’ve always been intrigued by them since the beginning of my interest in Deep Learning, mainly for the incredible results that they could produce. When I think of the term Artificial Intelligence, GAN is one of the first words that come to my mind.

Faces generated by GANs (StyleGAN)

But only when I started training them for the first time I discovered the double face of this interesting kind of algorithm: it is incredibly difficult to train. And yes, I knew that before trying myself from papers and other people that tried before me, but I’ve always thought that they were exaggerating an otherwise small and easy to overcome problem.

I was wrong.

As soon as I tried to generate something different from the traditional MNIST example I found out the huge instability problem that affects GANs and, as the hours spent trying to find a solution increase, becomes extremely annoying.

Now, after spending countless days researching known solutions and trying to come up with new ones, I can finally say I have at least more control over the stability of convergence in my GAN projects, and so can you. I’m not promising you a 10 minute solution to achieve perfect convergence (or in game theory words, Nash Equilibrium) in each one of your projects, but I would love to give you some tips and techniques you can follow to make your GAN journey a bit easier, less time-consuming and above all, less annoying.

State of GANs at Present Day

Since the birth of Generative Adversarial Networks and consequently their stability problems, a lot of research has been conducted. Nowadays we have a large number of papers proposing methods to stabilize convergence, with long and difficult mathematical proofs besides them. Moreover, some practical techniques and heuristics surfaced the Deep Learning world: I noticed…