For the past three years, I have led Machine Learning and Data Science at DataArt, researching the pain points of different businesses, proposing technological solutions and carrying out implementation.

In my time working with technology, I have identified eight key rules I use.

1. If the instrument exists, don’t reinvent the wheel

Not invented here syndrome. Image: source.

A popular in the technical community idea to build bespoke solutions for every new problem. Many engineers truly believe that their very customized approach, built to fit the exact business case is a better idea than taking a solution from the shelf and adjusting it to the particular case.

Cloud providers are rapidly developing ML services, treading the same path that Big Data services did before them. Ten years ago, Big Data was a pricey, easily-scalable and fault-tolerant exotic fruit. Now it’s standard. The same goes for open-source instruments. In 99% of cases, you don’t need to invent a new library or a database because most probably you’ll find something that works on the market.

2. Always consider business value and ROI

Every technical task should bring business value. If you do research, you should always be able to provide an example of a case you’re working on in real life. Usually, if you cannot quantify such a case, there’s no need to spend time on it.

ROI calculation methodology may need to be recalibrated. Compared to classical programming, machine learning is a probabilistic approach that never provides you with 100% accuracy, so you should always evaluate if increasing accuracy by 2, 5, 10, or 20 % worth of the investment made.

The good news is that data science projects are very close to the business, so you should have a great feeling of return.

Let’s say you have hundreds of people whose work is to extract data from the documents, then adding 5% to the accuracy of the results of automated extraction may mean millions of dollars per year. But if adding 1% to accuracy costs tons of money, a popular case in computer vision projects, maybe there are more valuable tasks and we still can rely on a human operator.

3. Never start research before the hypothesis is formulated

Often, business people set the question in a way: “We have tons of data, how can we make sense out of it? Can you help us find insights?”

Never start working on this without a clear hypothesis, otherwise, it’s looking for a needle in a bundle. Think of machine learning as of a supermind that does one thing well — automates what you cannot handle manually due to lack of computation power. If you cannot answer what you’re looking for, most probably you’re doing some random things.

Always start with the questions like:

What kind of problem I’m trying to solve?

What kind of question I’m trying to answer?

4. Integration with existing systems must be treated with sensitivity

Integration itself is not a big deal. But be sure to factor in human perception. If the company has a rule-based system, that makes decisions and it’s clear how it works, a new solution that uses ML-techniques can look like a black box to stakeholders. It’s therefore vital to have a clear migration plan that addresses potential risks.

We worked with a business travel company, which, among other things, was purchasing airplane tickets for its clients. Booking took 17 hours at which time the price could fluctuate. Fluctuation can depend on many factors: passenger flow, day of the week, time of the day, season, major sport or cultural events, weather, etc. The goal was to prove that analyzing historical data, with the help of ML, prices could be lowered to several percent on top of the existing reductions being produced by an old but proven rule-based system.

But no one wants to rely on a black box having a turnover of one billion dollars. A migration plan was elaborated: first an ML-based predictor was set up in parallel with the production system, followed by the processing of 10% of purchases in production, then 30%, constantly measuring relative performance. When the system is proven in production, at least 10% of the tickets will still need to be purchased via the old rule-based algorithm to get the latest updates of the sales engine to avoid overfitting (the state of the ML system when it thinks it knows everything about the world around).

It’s very important to demonstrate to all stakeholders that the ML process is very gradual and reversible in case of failure.

5. Do versioning

Every new version of your ML model is an experiment. It may be successful or not, that’s why you should always have a working CI/CD pipeline to be able to reverse to an older version.

However, you should also not forget about proper versioning of the data, the model parameters, and the results of experiments. There are specific tools to help here, such as DVC — a version control system for ML.

6. Don’t let the wheels spin in research: stay goal-focused (but don’t ignore great accidental discoveries)

It’s easy to get caught by the routine of research when you start looking into one problem, then find another one and then you find yourself in a completely different place, not really important for the product.

Stay focused on your research, don’t get distracted, remember why you started and what the main goal is.

However, if you see a low-hanging fruit that may be valuable for the user — go get it! This is especially likely to happen when you conduct visualizations to represent the insights found in data. Formally, it might not be critical at the time, but you never know what could be valuable for the business at some point.

Remember how great it is to receive minor but lovely updates in your favorite apps.

7. Be creative!

There’s always a complicated and accurate way of solving problems with a lot of data wrangling, feature engineering, meaning days of manual routine. But can you keep it simple bringing 80% of the result with 20% of efforts?

We have learned to apply lateral thinking on top of data. In one case, we needed to classify processes by business units in a huge chemical company. We found a workaround alternative to manual input by using publicly-available NLP models, converting the process and department phrases to vectors and finding the closest pairs.

Once we needed to sort 20 years-worth of marketing materials containing Mastercard logos to find which materials are still actual. Tens of thousands of documents. At some point, we realized that the last logo change for Mastercard happened in 2016. Two hours to label and train the cloud-based image recognition service, and voila — we had only fresh documents left.

We always lack data or expertise in data science projects, so creativity is an essential asset for building a working solution.

8. The human element — be sensitive and manage expectations

New technology such as ML comes with a set of challenges not thrown up by more established tech. One of the main issues with technology as new as ML is ensuring that proposed solutions don’t end up frustrating the management because of the inevitable uncertainty it causes.

ML and data science are a black box for the majority of people around, that’s why expectation management is more important than it’s ever been. Don’t forget to educate people, quantify the results of research to compare it with the goals, and think about the integration in advance both from the technical and the human point of view.

And, where appropriate, a combination of AI, heuristic methods and manual routine is fine. When people start building an AI-based solution, there’s often an intent to build something fully automated — an oracle with bells and whistles that can make recommendations with absolute certainty.

You’re lucky if this is possible, but don’t forget that even if ML doesn’t allow you to solve the task completely, it can be a lot of help in preparing the data required to make a decision. Taking the ultimate decision away from ML helps to avoid distrust from industry specialists, who usually prefer the final word to be a human one.

What are your insights? Please share in comments.