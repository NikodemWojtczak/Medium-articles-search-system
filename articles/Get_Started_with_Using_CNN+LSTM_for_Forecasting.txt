Get Started with Using CNN+LSTM for Forecasting

A method you should consider when you have data of low granularity with recurring local pattern Yitong Ren · Follow 4 min read · Mar 11, 2019 -- 6 Listen Share

Predicting the trend has been an ancient discipline yet it’s never fallen from popularity. Whether it is stock price in financial market, power or energy consumption, or sales projection for corporate planning, a series of time-based data points can be the representation of how the world is thinking in any given moment, which has always fascinated me. The capability to see and react ahead of time is an important factor to succeed in many aspects of life.

Photo from Unsplash

Time Series model is very effective when there are clearly trend, seasonality or autocorrelation in the data. However, the real world situation is far more complex that is impacted by multiple factors including economic phenomena, media effects, competitors’ behaviors, or even short-term fluctuations. These factors are manifest especially when forecasting reaches to the granular level such as hours, or minutes. LSTM (long short-term memory) is a recurrent neural network architecture that has been adopted for time series forecasting. I have been using stateful LSTM for my automated real-time prediction, as I need the model to transfer states between batches. Recently, I found adding convolutional layers to capture local, temporal pattern on top of LSTM layers can be immensely helpful in certain scenarios. In this post, I will use a simple example to demonstrate this architecture. I also strongly recommend Jason Brownlee’s blog posts of deep learning for time series. I personally benefit a lot from this series.

The Data

For this demonstration, I used the individual household electric power consumption data from UCI machine learning repository. I resampled the data over hours. In this post, I focus on the global active power attribute and disregard other variables. The data looks as below:

2. Problem Statement

In this problem, I want to use the 24 hours’ power consumption from the previous day to generate the next day’s 24 hours’ number. The data is from 2006/12 to 2010/12. I used the first two years’ data as training and the last two years’ as validation. So essentially this is a sequence to sequence prediction problem.

3. Model Architecture

I used a 1D convolutional layer followed by a max pooling layer, the output is then flattened to feed into LSTM layers. The model has two hidden LSTM layers followed by a dense layer to provide the output.

CNN-LSTM structure

The data is first reshaped and rescaled to fit the three-dimensional input requirements of Keras sequential model. The input shape would be 24 time steps with 1 feature for a simple univariate model. Within the convolutional layer, I didn’t further split the sequence into multiple subsequences but keep the timesteps to be 24 instead. And I chose the kernel size to be 3. The dense layer has 24 neurons to produce 24 output number. Below is a detailed model summary.

As you can see, I used a batch input size of 24. This is because, in this problem, which is also the case of many real-world situations, I want to predict on a daily basis. The number of batch size needs to be divisible by 24. In the end, I fit the model for 20 epochs and output the loss. I used mean squared error loss function and Adam optimization (Adaptive Moment Estimation).

4. Final Thoughts

Whether you should use RNN or CNN or hybrid models for time series forecasting really depends on the data and the problem you try to solve. I would go with a simple model if it serves the purpose and does not risk to overfit. This example aims to provide a simple guide to use CNN-LSTM structure. I believe this particular data can be fit better with a multivariate LSTM model.

References: