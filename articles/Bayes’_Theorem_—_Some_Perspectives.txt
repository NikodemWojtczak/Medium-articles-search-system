Bayes’ Theorem — Some Perspectives

Recently I am reading books related to history of mathematics, which reminds me of the fact that all complicated-looking equations started from a small, real world problem. The benefits of studying small problem are that it can help us ignore the leaves and focus on the trunk, and more importantly it allows us to translate back and forth between the complex theories and real world examples.

Motivated by such a belief, I started to apply this strategy to a theorem that I have learned long time ago but I am not quite intuitively familiar with and able to apply it quickly to any situations I encounter in real world — the Bayes’ theorem. Just as you know, the Bayes’ theorem is famous in data analytics and statistics, and is the backbone of many machine learning models and algorithms.

I will investigate some small examples and try to give you some intuitive explanations of the theorem in the following parts. Although the below discussions might be familiar to people from a statistics background, I feel like it is not trivial to have a deep and intuitive understanding if you never spend time really think and work on it. To get the most out of this, you are advised to take a pen and paper with you and follow through the calculations. The calculations are very simple, but writing them down on your own leverages your muscle memory and guarantees you a deep impression.

The Question

First of all, we need to have problem or question that we are interested in and collect some data to analyse it. A simple example will be used here, but mathematics is so general that of course you can apply it to any problems you want!

The problem I would like to investigate here is the relationship between academic qualifications and the wealth of a person. One of the question interests me is that how likely that a person is wealthy given s/he got a bachelor degree? Of course, it is not meant to imply the causality between the two but just the likelihood of one given another.

The Setup

Obviously, we would need to define the random variables and notations in order to apply the theorem. Let the wealth of a person be a random variable Y and the academic qualifications of s/he be a random variable X. The probability of Y taking assignment of y is written as P(Y=y) or P(y), the probability of Y taking assignment other than y is P(Y=~y) or P(~y). Similarly for X.

The Bayes’ theorem is defined as

Data Collection and Processing

Let’s start collecting data! I can immediately come up with some people in my mind. Here is the table showing relevant data of them .

Data of the friends I know. Numbers are made up. Ohh...yeah, Elon is my friend, he always talk to me (in youtube) but I am not sure if he also treats me as friend :(

To simplify things, I categorised the data into groups according to the following rules.

You may notice some issues of my way of collecting data. Please see the section Discussion of the Data. We will ignore the issues for now as we mainly want to have some intuitive understandings of the Bayes’ theorem.

Applying the Bayes’ Theorem

The question I am interested in is: what is the probability of being super wealthy given that I got a bachelor degree? Formally, I am asking P(Y=3|X=2). According to Bayes’ theorem, it is equal to the joint probability P(X=2,Y=3) over the marginal probability P(X=2)…(1). We can further divide the numerator into P(X=2|Y=3)*P(Y=3) and denominator into P(X=2|Y=3)*P(Y=3) + P(X=2|Y=2)*P(Y=2)+P(X=2|Y=1)*P(Y=1)…(2).

Now, we can directly lookup the data to determine the values of each component. For example, to find out P(X=2|Y=1), we first count the no. of records where Y=1, which is 5 in this case. We also need to record the no. of rows where X=2 and Y=1, which is 1 in this case. So P(X=2|Y=1) is 1/5. To calculate P(Y=1), we just need to count the no. of records where Y=1 among all the records, which is 5/10. We repeat the steps to determine the values of all the elements to get the results of …(3).

Some Observations and Interpretations

Dividing the condition: Observed that the denominator P(X=2) is divided into P(X=2| Y=3 )*P( Y=3 ) + P(X=2| Y=2 )*P( Y=2 )+P(X=2| Y=1 )*P( Y=1 ). What does it mean? It means that the world of X=2 is divided into different settings of Y . Observed that, for example, P(X=2|Y=3)*P(Y=3) = P(X=2,Y=3). Now, you can see that P(X=2) is divided into {P(X=2, Y=1 ), P(X=2, Y=2 ), P(X=2, Y=3 )}. Summing {P(X=2, Y=1 ), P(X=2, Y=2 ), P(X=2, Y=3 )} gives you back P(X=2). In words, the world of people holding bachelor degree is divided into {(people holding bachelor degree and being poor), (people holding bachelor degree and having medium wealth), (people holding bachelor degree and being super wealthy)}. Marginalising over the state of the wealths give you back the world of people holding bachelor degree.

Observed that the denominator P(X=2) is divided into P(X=2| )*P( ) + P(X=2| )*P( )+P(X=2| )*P( ). What does it mean? It means that . Observed that, for example, P(X=2|Y=3)*P(Y=3) = P(X=2,Y=3). Now, you can see that P(X=2) is divided into {P(X=2, ), P(X=2, ), P(X=2, )}. Summing {P(X=2, ), P(X=2, ), P(X=2, )} gives you back P(X=2). The numerator also constitute part of the denominator: Observed that P(X=2|Y=3)*P(Y=3) appear in both numerator and denominator when we rewrite the equation into …(2). P(X=2|Y=3)*P(Y=3) is actually P(X=2,Y=3). It means that we are measuring the proportion of the interested joint P(X=2,Y=3) in the world of denominator, P(X=2), which consists of other joints that are both are X=2 but have different assignment of Y.

Observed that P(X=2|Y=3)*P(Y=3) appear in both numerator and denominator when we rewrite the equation into …(2). P(X=2|Y=3)*P(Y=3) is actually P(X=2,Y=3). It means that we are measuring the proportion of the interested joint P(X=2,Y=3) in the world of denominator, P(X=2), which consists of other joints that are both are X=2 but have different assignment of Y. Interpreting the divided world in the denominator — they are just ratios times proportion: take the greenish parts in …(2) and …(3) as an example (P(X=2|Y=1)*P(Y=1) ). P(X=2|Y=1) means the no. of X=2 in the world of Y=1, so it is 1/5 (5 rows satisfying Y=1 and 1 row satisfying X=2 in the world of Y=1). You can also interpret it as a ratio: the no. of X=2 per Y=1. With this ratio, we can multiply by an appropriate proportion, P(Y=1), the no. of Y=1 in the universe of our data. Now the result of this multiplication is the total no. of people who are both X=2 and Y=1, and yes this is the joint. We do these not only for one setting of Y (Y=1) but all setting of Y (Y=1, Y=2, Y=3). In words, the greenish parts mean we try to find out the total no. of people who got a bachelor degree and have medium wealth by the ratio of no. of bachelor degree holders per medium wealthy person times the total no. of medium wealthy people.

Now you know the components of the denominator. Think about it in the normal Bayesian setting: Y is our models or beliefs and X is our data. The denominator consists of the ratios of the likelihood of the data in the world of a model, multiply by the prior probability of that model! We do these for all of our models to get the denominator, and put the one that we are interested in in the numerator, now we get a proportion called posterior!

Assisted with the above understandings, the below sections will discuss how Bayes’ theorem can help us understand the biases we human have.

The Source of Human Bias — Ignoring other evidence

In my opinion, the Bayes’ theorem can give us some clues to explain some biases that human has. Why so? Let me ask you: do you think normal people can distinguish the differences between the conditional probability P(Y|X) and the joint probability P(X,Y)? Probably not. Human uses eyes as sensors to receive information. We see things and associate things that appear together, which is effectively the joint events (joint probability). To find out the conditional probability, we will need to do some further processing, and human is very unlikely to do so especially when they need to react fast using their “fast system” [1]. YET, sometimes there is no harm for them to be ignorance of fact that the joint and the conditional are different and they may even be “rightful” to do so. Why? because P(Y|X) is the direct variation of P(X,Y), so people are “justified” to use P(Y|X) to approximate P(X,Y). However, on some occasions it would cost us to do the approximation.

Let’s investigate another example. Supposed I was having lunch at restaurant located at a central business district. My friend told me that the people working in financial firms are required to wear suits. This is actually saying that the conditional probability P(a person wearing a suit|a person working in financial firms) is high, and we are near the financial centre so P(a person working in financial firms) is also relatively high. Thus, the joint probability P(a person wearing a suit, a person working in financial firms) is also quite high. Then, a person wearing a suit come in, I naturally ask: how likely is that person working in financial firms?

You might think, quite likely, right? But the probability might not be as high as you might think. Why? Because there are also lots of lawyers, government officials and staff of restaurants working nearby and they are all required to wear suits!(equivalently, this is saying P(a person wearing a suit, a person working in non-financial firms) = P(a person wearing a suit|a person working in non-financial firms)*P(a person working in non-financial firms) is also “high”.) So, just observing a person wearing a suit could not help us much in determining where the person works. If we ignore the counter case that a lot other people also need to wear suits, we are in trouble making the judgment that P(a person working in financial industry|a person wearing a suit) is high.

Therefore, source of the bias is that we sometimes ignore the counter case. Recalled that P(y|x) = P(x,y)/(P(x,y)+P(x,~y). If the counter case P(x,~y) is rare, we could safely ignore it to use P(x,y) to approximate P(y|x). However, when the counter case P(x,~y) is also very common, the denominator becomes large and P(y|x) becomes “smaller”, or at least not as high as you might originally think.

(Exercise: Supposed that your father has beard (and you have not met him for a long time). What is the the probability that the person you encounter in the street is your father given the person has beard?)

The Source of Human Bias — Ignoring the Prior

Let Y be a person is a professor, X be a person brining a book.

Supposed I observed that professors always love to bring a book with them (P(x|y) is high). I sat at a restaurant. A man with a book with him came in, what is the probability that he is a professor P(y|x)?

Well, you might think it is high as not many people bring a book with them. This might be true, but the thing is professors are very rare and I am unlikely to meet one normally (so P(y) is low)! If the prior probability that observing a professor is super low, then the numerator of P(y|x) would be very low as well!

(Exercise: What is the probability of getting an acoustic neuroma (a type of rare cancer) given the symptoms of feeling dizzy is observed?)

The Source of Human Bias — Not really knowing what we are asking

Alternative titles for this section could be: Confusing P(X|Y) and P(Y|X), or Knowing Your Question. At first, I feel asking “What is the likelihood for me to get rich if I have a bachelor degree” is almost the same as “What is the likelihood for a rich person to have bachelor degree”. In fact, it could be totally different.

The likelihood for me to get rich if I have a bachelor degree is P(Y=3|X=2). It is the proportion of rich and bachelor degree holder (P(X=2,Y=3)) in the world of bachelor degree holders P(X=2).

On the other hand, the likelihood for a rich person to have bachelor degree is P(X=2|Y=3). It is the proportion of rich and bachelor degree holder (P(X=2,Y=3)) in the world of rich people P(Y=3).

The numerators in both cases are the same (P(X=2,Y=3)), but the denominators are different. If the world of the denominator is a large one (e.g. P(X=2) is large), chances are there are lots of possible counter cases (e.g. P(X=2,Y !=3) are large), making the result of interests small (e.g. P(Y=3|X=2) becomes small).

(a side note: knowing that to calculate P(X|Y) or P(Y|X) both requires P(X,Y), you know the flexibility, importance and power of having found a joint distribution P(X,Y) when you do inference and prediction. You can sum P(X,Y) over X to get P(Y) to help you calculate P(X|Y), or you can sum P(X,Y) over Y to get P(X) to help you calculate P(Y|X). Of course, P(X,Y), also called a generative model, is difficult to model.)

Discussion of the Data

The data collection method I used is not random sampling. This is problematic if the population I concerned is the all the people but I only include people that I am familiar with. The samples are not representative enough for the whole population.

Besides, the way I discretise the continuous data (the net worth) is subjective, and could have large influence on the result especially if the dataset is a large one.

Things Not Discussed Here

Only two random variables are used in the above examples and they are both discrete. This is done so to allow us to focus on the trunk and understand the calculations of Bayes’ theorem. However, there are some more interesting cases when more random variables are involved, and it is more obvious in the field of probabilistic graphical model, which I am also working on.

Probability distribution model is not discussed here for simplicity. Bayesian statistics treated the parameters of a probability distribution as random variables, which is not mentioned as well.

Conclusion

This article used several simple real life examples to go through the concepts and calculations of Bayes’ theorem and see why some human biases arise. I hope this article can crystallise the equation for you and you can have a deeper understanding of this important theorem!

Thanks for your time and I would love to know your thoughts :)

Reference

[1] Daniel, K. (2011). Thinking, fast and slow. Allen Lane, New York, USA.

[2] Blitzstein, J. K., & Hwang, J. (2014). Introduction to probability. Chapman and Hall/CRC.