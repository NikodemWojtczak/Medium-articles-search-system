DATA SCIENCE FROM THE GROUND UP

The Basics: Decision Tree Classifiers

Decision trees are a conceptually simple and explicable style of model, though the technical implementations do involve a bit more calculation that is worth understanding. Still, the intuition behind a decision tree should be easy to understand. Indeed, decision trees are in a way quite similar to how people actually make choices in the real world.

What

When confronted with a choice to make, real people might think in a series of cascading decisions. If I need to choose what to wear in the morning, I don’t pick an outfit randomly out of the closet, I first breakdown my options. For starters, I probably already have heavy winter clothes and lighter summer clothes separated. I then might check the weather, further narrowing down the range of outfits — if it’s raining I might want to wear my boots, say. Finally, I may consider what plans I have today and if I need to dress up for any reason. You can think of my decision process as starting with all the options in my closet, and then progressively narrowing down my choices until I’m picking from a much smaller set of options.

Perhaps we can teach the computer to make decisions or predictions in a similar way. One aspect is that the decision making process is rules based, which makes it easy to implement on a computer, assuming we know what the rules are. The task therefore is finding what the rules are.

Consider a simple classification problem. Here are points scattered among three categories:

A simple three category classification problem

If presented with a new point somewhere on the grid, how would you predict which category it belonged to? You might start by noticing, say, that all the points in the upper portion of the grid are orange. So, let’s start by simply drawing a horizontal line at the bottom of this ‘orange territory’. If the new point we’re trying to predict falls above this line, we’ll guess it belongs to the orange category: