Fig: First 5 categories of images, seen only by the first neural network.

But we are actually interested in building a neural net for the last 5 categories of images — dog, frog, horse, sheep, or truck.

Fig: Last 5 categories of images, seen only by the second neural network.

Next, we define two groups/types of layers: feature (convolutions) and classification (dense).

Again, do not be bothered about the implementation details of these code snippets. You can learn the details from any standard tutorial on Keras package. The idea is to understand the concept.

The feature layers:

feature_layers = [ Conv2D(filters, kernel_size, padding='valid', input_shape=input_shape), Activation('relu'), Conv2D(filters, kernel_size), Activation('relu'), MaxPooling2D(pool_size=pool_size), Dropout(0.25), Flatten(), ]

The dense classification layer:

classification_layers = [ Dense(128), Activation('relu'), Dropout(0.25), Dense(num_classes), Activation('softmax') ]

Next, we create the complete model by stacking together feature_layers and classification_layers.

model_1 = Sequential(feature_layers + classification_layers)

We then define a function for training the model (not shown) and just train the model for certain number of epochs to reach a good enough performance:

train_model(model_1, (x_train_lt5, y_train_lt5), (x_test_lt5, y_test_lt5), num_classes)

We can show how the accuracy of the network evolved over training epochs:

Fig: Validation set accuracy over epochs while training the first network.

Next, we freeze feature layers and rebuild the model.

This freezing of feature layers is at the heart of transfer learning. This allows re-use of pre-trained model for classification tasks because users can just stack up new fully-connected layers on top of the pre-trained feature layers and get good performance.

We will create a fresh new model called model_2 with the untrainable feature_layers and trainable We show the summary in the figure below: classification_layers.

for l in feature_layers: l.trainable = False model_2 = Sequential(feature_layers + classification_layers)

Fig: The model summary of the second network showing the fixed and trainable weights. The fixed weights are transferred directly from the first network.

Now we train the second model and observe how it takes less overall time and still gets equal or higher performance.

train_model(model_2, (x_train_gte5, y_train_gte5),(x_test_gte5, y_test_gte5), num_classes)

The accuracy of the second model is even higher than the first model, although this may not be the case all the time, and depends on model architecture and dataset.

Fig: Validation set accuracy over epochs while training the second network.

The time taken for training two models are shown below:

Fig: Training time for the two networks.

What Did We Achieve?

Not only did the model_2 train faster than model_1, it also started at a higher baseline accuracy and achieved better final accuracy for the same number of epochs and identical hyperparameters (learning rate, optimizer, batch size, etc.). And it achieved this training on images which were not seen by model_1.

This means that although model_1 was trained on images of — airplane, automobile, bird, cat, or deer — it’s learned weights, when transferred to model_2, helped model_2 achieve excellent performance on the classification of completely different categories of images — dog, frog, horse, sheep, or truck.

Isn’t that amazing? And you can now build this kind of transfer learning with so few lines of codes. Again, the entire code is open-source and can be found here.

Originally published at https://blog.exxactcorp.com on October 23, 2019.