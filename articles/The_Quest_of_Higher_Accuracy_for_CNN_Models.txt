The last 4 columns show the highlights of all the performance improvement techniques we are applying while defining the model as well as during data processing. In general while doing performance measurement its recommended to change one variable at a time, the table shows only such runs where we see some performance improvement or if we have applied any new tuning technique.

All the measurements are done on NVIDIA Quadro M400 GPU. This GPU has a 8 GB RAM. GPU is configured with CUDA 9.0, cuDNN 7.4, TF for GPU 1.8.0 on Ubuntu 16.04 instance.

Some of the limitations of these measurements

Since the GPU had only 8 GB of memory, you need to carefully design the data pipeline and the model otherwise you will frequently get “Resource Exhausted Error”. You can easily circumvent this issue by reducing batch size, reducing image size while loading the data and changing number of trainable parameters in the model by removing few CNN layers or introducing a MAX pooling layer. During my experiments I have tried all possible max values. Since majority of the codes use flow_from_dataframe functionality to load the images. It restricts us from doing feature-wise normalization and setting image mean to 0 by using feature-wise center (Keras functionality provided by ImageDataGenerator). In order to use these 2 features we need to fit the data which is in NumPy array (image.load_img) format. Unfortunately the VM instance which I am using takes long time to read the data into NumPy array.

Now lets take a look at the code where we got 80% accuracy

This code uses Linux packages such as mat-plot, NumPy, Keras, Pillow, H5py and Tensor-Flow.

I have already downloaded the database from Kaggle. The database has several zip files, we need to unzip them into train/test folders containing respective images. All the labels for train images are provided in a separate CSV file.

In the code below we will read a CSV file containing labels and name of the images. We need to do some sanity checks (adding .jpeg extension, delete all the images of size 0 KB, remove entries of deleted images from the data frame) before we move forward.

Lets split the database into train and validation data and then convert the labels into one hot encoded labels. We are purposefully doing one hot encoding after splitting the data to retain the original label format to compare the labels to the predicted once later. (This will be useful when we retrain on wrongly predicted images) We will also calculate class weights since this is a highly imbalanced database.

As I said before we will use ImageDataGenerator (to apply all image augmentation techniques, image rotations, width/height shift and re-scale) and flow_from_dataframe (to read all the images, set batch size and image size)

Lets define the model. This model consist of 2 dimensional convolution layers with Relu as activation function, zero padding layers and max pooling layers. We will be also implementing batch normalization and L2 regularization. This is a Keras functional API implementation.

Initialize the optimizer and loss function. We will be using stochastic gradient descent (SGD) with a learning rate of 0.01 which will be decaying every epoch. In practice SGD is 2 dimensional function but the neural network might have millions of parameters which means the millions of directions the loss function can move. If the loss function has a local minimum point/saddle point, there will be “zero gradient” and the gradient descent will get stuck. If we add momentum to SGD, the saddle points will get velocity to move forward. Adding nesterov momentum will take shorter path towards convergence.

Callbacks will help us retain the best weights and biases we trained so far, since we will be training with multiple epochs and each epoch will go through entire training set. There is always a possibility that the model is over-fitting after certain number of epoch or accuracy may stop improving, the already saved weights will be helpful.

The model we defined looks like below

_________________________________________________________________

Layer (type) Output Shape Param #

=================================================================

input_3 (InputLayer) (None, 256, 256, 3) 0

_________________________________________________________________

conv2d_33 (Conv2D) (None, 254, 254, 16) 448

_________________________________________________________________

conv2d_34 (Conv2D) (None, 252, 252, 16) 2320

_________________________________________________________________

batch_normalization_17 (Batc (None, 252, 252, 16) 64

_________________________________________________________________

zero_padding2d_5 (ZeroPaddin (None, 254, 254, 16) 0

_________________________________________________________________

conv2d_35 (Conv2D) (None, 252, 252, 32) 4640

_________________________________________________________________

conv2d_36 (Conv2D) (None, 250, 250, 32) 9248

_________________________________________________________________

batch_normalization_18 (Batc (None, 250, 250, 32) 128

_________________________________________________________________

conv2d_37 (Conv2D) (None, 248, 248, 64) 18496

_________________________________________________________________

conv2d_38 (Conv2D) (None, 246, 246, 64) 36928

_________________________________________________________________

batch_normalization_19 (Batc (None, 246, 246, 64) 256

_________________________________________________________________

max_pooling2d_5 (MaxPooling2 (None, 123, 123, 64) 0

_________________________________________________________________

zero_padding2d_6 (ZeroPaddin (None, 125, 125, 64) 0

_________________________________________________________________

conv2d_39 (Conv2D) (None, 123, 123, 128) 73856

_________________________________________________________________

conv2d_40 (Conv2D) (None, 122, 122, 128) 65664

_________________________________________________________________

batch_normalization_20 (Batc (None, 122, 122, 128) 512

_________________________________________________________________

conv2d_41 (Conv2D) (None, 120, 120, 64) 73792

_________________________________________________________________

conv2d_42 (Conv2D) (None, 118, 118, 64) 36928

_________________________________________________________________

batch_normalization_21 (Batc (None, 118, 118, 64) 256

_________________________________________________________________

conv2d_43 (Conv2D) (None, 116, 116, 64) 36928

_________________________________________________________________

conv2d_44 (Conv2D) (None, 114, 114, 64) 36928

_________________________________________________________________

batch_normalization_22 (Batc (None, 114, 114, 64) 256

_________________________________________________________________

max_pooling2d_6 (MaxPooling2 (None, 57, 57, 64) 0

_________________________________________________________________

conv2d_45 (Conv2D) (None, 55, 55, 64) 36928

_________________________________________________________________

conv2d_46 (Conv2D) (None, 53, 53, 64) 36928

_________________________________________________________________

batch_normalization_23 (Batc (None, 53, 53, 64) 256

_________________________________________________________________

conv2d_47 (Conv2D) (None, 51, 51, 128) 73856

_________________________________________________________________

conv2d_48 (Conv2D) (None, 50, 50, 128) 65664

_________________________________________________________________

batch_normalization_24 (Batc (None, 50, 50, 128) 512

_________________________________________________________________

flatten_3 (Flatten) (None, 320000) 0

_________________________________________________________________

dense_7 (Dense) (None, 32) 10240032

_________________________________________________________________

dropout_5 (Dropout) (None, 32) 0

_________________________________________________________________

dense_8 (Dense) (None, 32) 1056

_________________________________________________________________

dropout_6 (Dropout) (None, 32) 0

_________________________________________________________________

dense_9 (Dense) (None, 5) 165

=================================================================

Total params: 10,853,045

Trainable params: 10,851,925

Non-trainable params: 1,120

_________________________________________________________________

Its time to train the model on a GPU

This is how the training will progress and you can see we achieved 80% training as well as validation accuracy.

Epoch 1/5

370/370 [==============================] - 1849s 5s/step - loss: 29.1990 - acc: 0.7959 - val_loss: 10.7663 - val_acc: 0.8000

Epoch 2/5

370/370 [==============================] - 2584s 7s/step - loss: 17.5359 - acc: 0.7999 - val_loss: 3.8036 - val_acc: 0.8000

Epoch 3/5

370/370 [==============================] - 2398s 6s/step - loss: 16.2506 - acc: 0.8000 - val_loss: 3.2556 - val_acc: 0.8000

Epoch 4/5

370/370 [==============================] - 2064s 6s/step - loss: 20347.928 - acc: 0.7999 - val_loss: 321.0431 - val_acc: 0.8000

Epoch 5/5

370/370 [==============================] - 2482s 7s/step - loss: 88.7576 - acc: 0.8000 - val_loss: 12.5082 - val_acc: 0.8000

We can also see how accuracy and losses are changing over time using below code

This is how the plots look

In order to further improve the accuracy, we will be retraining on wrongly predicted training images. For this we will load the model that we just saved, later we will use the predict_generator to predict on the same training images. In this way we will be fine tuning model to specific set of images for which previous model miss predicted.

Now we have a new database in df_filtered. we can use same old data pipeline and model definition we used earlier. This retraining allowed me to reach up to 82% accuracy.

GitHub Repository

All the iPython notebooks are available at https://github.com/swanandM/Diabetic-Retinopathy-Detection-with-TF

What else we can do to improve the accuracy?

Sometime in real world scenario its difficult to relay on single model. Different models can have different properties depending on number of layers it had, number of parameters it is trained on, etc. A particular model may not be able to predict best on particular set/type of images. In such cases we can combine multiple models to make a best prediction.

In my next article, we will implement model ensembles by using some of the best performing models which we already created. Model ensembles can be used to take a vote from those models to make final prediction.

References