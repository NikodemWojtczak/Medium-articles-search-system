An Overview of Japanese NLP Libraries

nagisa-tutorial-pycon2019

PyCon JP 2019 is held in 2019/9/16~ 2019/9/17 for two days. I will publish some posts about the talks I am interested in.

As an NLP engineer, I am happy to find a talk related to NLP. This post is a brief English summary of the nagisa talk from Taishi Ikeda. You can find the slides here and the tutorial here in Japanese.

Two libraries

There are tons of Japanese NLP libraries but how to choose a good one for use needs some research. Thanks to Taishi Ikeda who save time for us. The figure above collect many Japanese NLP libraries and make a pretty detail comparison among them. If you don’t know Japanese, no need to worry. I just recommend two tools, Juman++ and nagisa.

A simple criterion to determine the performance is that whether a library has provided a neural-based model for prediction. In other words, do the maintainers update the library along with the technologies development? According to Taishi Ikeda, Juman++ and nagisa are the only two libraries that provide the neural-based model.

nagisa

Because Taishi Ikeda’s talk is mainly about nagisa I will briefly introduce nagisa. The model used by nagisa is the Bi-LSTM-CRF. The CRF layer is ignored because he don’t want to confuse those people who is not familiar with NLP.

The corpus that nagisa trained on is KWDLC. And nagisa performs well especially on the emoji symbols

Taishi Ikeda is very kind to provide the Colab notebook for quick play.

Reference