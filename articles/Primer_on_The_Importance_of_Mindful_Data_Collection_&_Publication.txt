Outline

There are differences in standards when it comes to data collection, privacy, and consent.

However, most people don’t have a say in how relevant policy decisions are made.

As data scientists, we need to be cognizant of how we handle data, where we publish it, how secure it is, and how it could harm people.

Introduction: Digital Footprints are Unavoidable

Perhaps it is an understatement to say that “data,” especially of the big variety, has been a topic of huge discussion not just among experts, but their nonexpert friends, random people on the internet, really any person that is still plugged into a network.

At this point, it feels like being a part of a network that collects your data is not a choice. Maybe it hasn’t been a choice for a long time, but the lack of choice is hard to deny now — can you imagine shutting off your cellphone where you have to take work calls, check in with people, or getting off of Facebook/Instagram/LinkedIn/Google where you find information, network, and connect to others, permanently?

On the one hand, this can seem frightening. Sites, for example, can track how far you scroll down an article, how many times you click on what links. People can call an API to get your tweets, your profile information, when you are clicking, on what. It is no wonder that science fiction books, dystopian novels, and the like seem to be around us all the time now.

On the other hand, the amount of data available is truly staggering in an exciting way. The possibilities seem endless, particularly for people interested in social research. There are new amazing tools and ways to measure social behavior like never before. Sites like Facebook, Twitter, and Google are so exciting because of how we can imagine mapping networks and new ways of interacting. However, for researchers, this adds a new and highly significant layer to maintaining the privacy of research subjects to an existing system of research oversight.

Data Collection: Institutional Review Board (IRB)

At any research institution, if you are conducting research on human subjects, you must first draft a proposal of your study, methods, justifications, etc. in accordance with the institution’s IRB. Then your study must be approved. According to the Electronic Code of Federal Regulations, there is a full set of criteria that must be met in order for IRB approval to be granted. Here are some of the criteria:

(1) Risks to subjects are minimized: (i) By using procedures that are consistent with sound research design and that do not unnecessarily expose subjects to risk, and (ii) Whenever appropriate, by using procedures already being performed on the subjects for diagnostic or treatment purposes.

Obviously, there is room for interpretation, and it is at the discretion of the IRB in question to determine whether or not a research study has met the first term of “minimized” risk. The IRB also considers the fact that not all humans have the same ability to decide whether or not to be a part of a research study or can necessarily make informed decisions or grant informed consent:

(3) Selection of subjects is equitable. In making this assessment the IRB should take into account the purposes of the research and the setting in which the research will be conducted. The IRB should be particularly cognizant of the special problems of research that involves a category of subjects who are vulnerable to coercion or undue influence, such as children, prisoners, individuals with impaired decision-making capacity, or economically or educationally disadvantaged persons.

Informed consent is always required. This is true of any research institution, even if you are conducting an undergraduate research study. The following two provisions are ones that data scientists need to be the most cognizant of:

(6) When appropriate, the research plan makes adequate provision for monitoring the data collected to ensure the safety of subjects. (7) When appropriate, there are adequate provisions to protect the privacy of subjects and to maintain the confidentiality of data.

The IRB process is slow, and sometimes certain social behaviors might take off, and the fact that you have to get approval before you can conduct the research, slows you down, and can make you lose precious time and data. But at the very least, it is a system of oversight that is regulated, documented, and whose main focus is on the research subjects.

However, the tech industry DOES NOT have Institutional Review Boards in the same way that research institutions do.

Many tech companies are able to conduct copious amounts of social research without the kind of oversight or discretion legally required by research institutions. This issue has been well-documented and has been up for debate for several years. (Below I have linked several articles that might pique your interest.) The differences in standards, when it comes to research, consent, privacy, and security, is not limited to the industry vs. academia divide. There is also no consensus internationally about how to handle data securely. The issues of differing standards can ultimately harm unsuspecting people who have their data scraped, mined, and analyzed without any knowledge.

Example: 2014 Facebook Happiness Study

In 2019, it is no secret that Facebook has our data, and probably knows us better than ourselves. It certainly knows who we interact with online, what we like, what we don’t like, how long we use it, what we buy, what we don’t buy, what we watch, the list goes on. In 2014, however, just 5 years prior, the extent to what Facebook does with that data became much clearer for the average user. A study was published, with a ridiculous number of research “participants,” an N so large, researchers could only dream of it: 600,000+ “participants.” But of course, the study was not reviewed by an IRB, informed consent was not given explicitly, and the results were quite controversial.

In an experiment with people who use Facebook, we test whether emotional contagion occurs outside of in-person interaction between individuals by reducing the amount of emotional content in the News Feed. When positive expressions were reduced, people produced fewer positive posts and more negative posts; when negative expressions were reduced, the opposite pattern occurred.

The above excerpt comes from the abstract to the article, entitled “Experimental evidence of massive-scale emotional contagion through social networks” (Kramer, Guillory, and Hancock 2014). While the authors acknowledge that the results of their study are controversial, it is hard to believe that this study could ever have complied with the kinds of IRB regulations listed above. Especially in this age where issues of mental health, depression, anxiety, and suicide are under constant discussion, it is no surprise that people were not so pleased when the study came out.

Data Storage & Publication: Show your work?

In the current era, in order to stay relevant and to be a part of the tech conversation, it is vital to show your work. People want to see your exploratory data analysis (EDA). People want access to your csv files, to your code. Show me your GitHub. Show me your notebooks. Show me your raw data. Show me your final data. This is all extremely important for research and data science to be conducted in a transparent and reproducible way for the sake of intellectual pursuit. But what about the people you’ve researched? What about their Personally Identifiable Information (PII)?

PII refers to information that can be used to identify someone. The obvious examples are social security number, birthdate + full name, etc. But some others are a bit less obvious: IP address, age, gender, and zipcode. There have been a number of combinations of less obvious data points that when put together tend to compose a set of identifying information.

For anyone that works with data about people, especially to those that are just starting to figure out how to draw inferences from your data, we have to think about how we store our data, how to actually encrypt the data, and in what form we should and should not post our data online. Is the information that you have fully anonymized? What does that mean? Is there any potentiality that the people whose data you have collected could be harmed because of your project?

Conclusion: We’re Still Working On It

It is perhaps unsatisfying to know that no perfect solutions have yet to be reached. In the last few years, people have been clamoring for more laws to regulate data privacy, and some lawmakers are trying to respond. Just in 2018, the EU passed the General Data Protection Regulation in an attempt to return some control back to the individuals that are generating their data. Given how new the technologies are, relatively speaking, and how quickly they are growing, right now, especially, it is imperative that people in the field remain vigilant and adamantly choose to protect people before they choose to protect their models.

Further Reading