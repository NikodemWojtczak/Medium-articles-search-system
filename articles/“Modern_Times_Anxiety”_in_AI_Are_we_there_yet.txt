“Modern Times Anxiety” in AI: Are we there yet? Prakhar Ganesh · Follow 4 min read · Sep 17, 2019 -- Listen Share

I recently came across this panel discussion from AAAI conference, 1984 and weirdly enough it felt both ancient yet relevant all at the same time and I was hoping I can throw my thoughts in this pit too.

The most obvious, what you might call the “1984 Big Brother Is Watching Anxiety,” is that somehow the computer will erode our freedom and invade our privacy.

I think the way we have simply accepted the whole ‘Privacy is a myth’ conundrum is a big reflection of what was considered a fear then has just become a part of our life now. While everybody values their privacy and are extremely protective towards it, we also have to acknowledge that most of us don’t really read the ‘Terms and Conditions’ before clicking ‘Accept’!!

.. a closely related anxiety might be called the “Modern Times Anxiety.” People becoming somehow, because of computers, just a cog in the vast, faceless machine; the strong sense of helplessness, that we really have no control over our lives ….. inevitably result in alienation, isolation, enforced conformity, standardization, and all those bad things-leaching away of humanity.

The Sky-High Expectations and the “AI Winter”

There’s a charge often leveled against AI people that they claim too much. To what extent is it due to naivete on the part of the public?

AI has always been a field aimed at trying to understand the working of a human mind, to make machines intelligent. And to be honest, in that regards, we are nowhere close to our original goal. However, there has been steady progress in the field in the last few years with some incredible success stories.

I think there is a pressing need for communication between the researchers and the general public. There are unrealistic expectations from people in AI and frankly, I have heard less ‘Wow’ and more ‘Didn’t the computers do that already?’ when talking about latest innovations with people who claim to follow the latest development in AI but don’t really know the field. And this level of expectation can be dangerous.

I don’t think this scenario is very likely to happen, nor even a milder version of it. But there is nervousness, and I think it is important that, we take steps to make sure the “AI Winter” doesn’t happen-by disciplining ourselves and educating the public.

AI Winter just refers to a stage when funding for AI projects start to dry because people are not getting what they expected. While a lot of you will say that with the recent success in the field, that is definitely not a possibility and I think I might agree with you.

But I think I should warn you, the people in this panel also thought the same and just half a decade later went through what a lot of experts call the second AI Winter!!

How much AI do these AI groups really know?

I got scared when big business started getting into this ….. they were all making investments- they all have AI group ..… those people weren’t trained in AI. They read an AI book, in many of these cases. They started off reading all the best AI research.

There is a tremendous demand for engineers and researchers in the field of AI and the supply is not as efficient as the demand, at least not the quality we should aim for. Most of the people working on the ground level in AI have entered the field through training of a year or even less and are calling themselves AI researchers.

I think that it’s wonderful that those people are being created …… They’re not researchers. The worry I have is that they will begin to think they are researchers. I don’t think we should make that demand of them ……… Ph.D research, at least in my laboratory, used to take three to four years. Now it seems to be taking five to six. It’s a long process. You have learn a lot of stuff and then try to create something on your own. That’s what a Ph.D means. All I can say is that that isn’t the same thing as being trained through tutorials.

Conclusion

I think this debate is as relevant today as it was back then. I think it is important to properly handle the expectations from this field and to train more and more ‘researchers’ that can do the job better. We need to be protective of who we are letting to be the face of AI research. I too want to be a researcher in the field, but I believe that going through the pipeline is important before I count myself among those pushing the field forward.