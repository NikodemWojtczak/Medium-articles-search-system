Below, I’ve paraphrased the following research question originally raised in Daniel Khaneman’s best-selling book Thinking, Fast and Slow:

Both the highest and lowest rates of liver cancer have been shown to exist in rural communities. Why?

I’ll return to this question at the end of the post. But for now, let’s discuss what knowledge stands to gain — and lose — from the unprecedented amount of information we are collecting about ourselves.

The standard definition of data science is: “a multidisciplinary field that uses scientific methods, processes, algorithms and system to extract knowledge and insights from structured and unstructured data.” As the information age continues to come to fruition, Internet connectivity and personal computing are almost ubiquitous. With every person under age 50 in a developed country constantly tapping at a phone screen, typing on a laptop, and enjoying all sorts of digital content, the world’s tech companies are amassing unprecedented amounts of data. The field of data science has emerged to both organize and optimize this data, often to improve the performance of digital services like the algorithms behind Amazon store product recommendations and Spotify’s “Discover Weekly” playlists. However, data science has also allowed us to study the intricacies of social behavior on a previously unimaginable level. As smart speakers enter our homes and intelligent cars hit the roads, we will only continue to gather more information about ourselves.

Data data data (Source: Ourworldindata.org)

However, having more data and information at our fingertips does not automatically translate to higher knowledge and understanding. Our ability to turn data into genuine insight still depends on properly exercising the scientific method. This is by no means a guarantee; according to some intellectuals, society has leaned heavily on unrefined science for decades.

Karl Popper, an Austrian-born British philosopher known for his views on falsifiability, the scientific method and his criticism of induction, encapsulates this cautionary line of thinking. Popper argued that true science depends on hypotheses that can be falsified. Scientifically rigorous theories make assumptions based on thorough research and logical examination, then use all available means to prove the hypothesis wrong. This type of science moves humankind forward; as Popper disciple Nassim Nicholas Taleb points out, Newton’s theory of motion did wonders for mankind’s understanding of physics despite being proved wrong by Einstein several hundred years later. Progress comes from finding assertions that cannot be proven wrong and relentlessly experimenting to disprove the theory.

Karl Popper

The dichotomy between deduction and induction perfectly encapsulates what Popper and his ilk view as the improper implementation of science. In the former, we deduce by moving from theory to hypothesis, to empirical observation, and finally, rejection of the hypothesis. Induction, on the other hand, uses empirical facts to detect patterns, generate hypotheses and formulate theories. Induction is harder to disprove and more dangerous because it allows us, as Taleb says, to be “fooled by randomness”. Induction may seem harmless on the surface but has pernicious side effects in reality; when you use historical data to build models operating under the assumption that housing prices can never go down, you run into trouble.

Popper went after social scientists who created sweeping, grandiose theories that seemed revolutionary on the surface but proved wobbly in practice. This is because these types of theories are impossible to disprove. For example, consider Sigmund Freud’s theory about the Oedipus complex. How could one possibly disprove that children are subconsciously sexually attracted to their parents? You can’t. Therefore this is an unscientific analysis no more rigorous than suggesting the existence of gods. Yet, in many circumstances, unscientific theories are widely regarded as truisms today. Mainstream economics is a perfect example of this phenomenon. This discipline’s models have become increasingly complex, mathematical, and detached from reality without showing any improvement in forecasting success. And as statistician Nate Silver put it: “Any illusion that economic forecasts were getting better ought to have been shattered by the terrible mistakes economists made in advance of the financial crisis.” [1]

When we exclusively use historical data, also known as empirical knowledge, to formulate theories, we create models that can be highly accurate on average but remain vulnerable to edge-case scenarios. Just as throwing more money at a problem doesn’t necessarily equate to solving that problem, adding more data to our models doesn’t necessarily make them any more reflective of the real world. By definition, models are a simulation, and with more data, it is tempting to overfit and mistake signal for noise. But the value of data is not in its overall mass but our ability to hone, shape and interpret it. It’s about the process.

A good data scientist should have a strong understanding of the scientific method, ask the right questions, and remain skeptical of empirical knowledge, especially when building models with severe consequences. And we should keep in mind that there is some truth to the statement “the more we learn, the less we know”; Einstein’s Theory of Relativity arguably created more questions about the universe than answers.

So if you deeply research social behavior in rural communities and use data science to analyze chemical exposures, lifestyle discrepancies, cultural norms, nutrition patterns, etc. I’m sure you could find some convincing results to explain why rural communities suffer from liver cancer at the highest AND lowest rates in America. When I first encountered this research question, I certainly racked my brain for answers like this. But Popper would be skeptical of using your empirical analysis to build a model to project future liver cancer rates in rural communities. Why?

Kahnman reminds readers shortly thereafter that rural communities have smaller populations than urban areas, so given their statistical distribution, they have a higher variance and more varied outcomes, leading to both higher and lower rates of cancer. The smaller sample size increases the effect of randomness. Humans are prone to creating stories and hypothesizing about causality when there is none, so our gut instinct is to come up with “scientific” explanations of events, even when the laws of statistics are a perfectly reasonable explanation of why cancer rates swing further in small rural communities. When we begin to investigate the treasure trove of information served to us on a platter of clicks and likes, it is important to keep the role of chance in mind and remain skeptical of empiricism.