Does your product work?

We build software to solve human problems. But human problems can be messy, and sometimes it’s not terribly clear whether or not we’ve actually solved them.

Snapchat might tell they’re successful if they see 50% of regular users check out their new dog filter, and Facebook could say they’ve shattered their growth milestones by showing they’ve achieved more than 2.3 billion monthly active users.

But what’s your acceptance criteria when your app is designed to help members cope with anxiety? What metric can you monitor when your software was built to cultivate mindfulness?

Or, in the case of my company—Even — how can we tell if we’re making any impact on the financial health of our members?

We have high engagement with our mobile app, we’ve sent our members more than a billion dollars’ worth of their earned wages, and we’re automatically saving millions for them in rainy day accounts. These are things worth celebrating.

But they aren’t enough.

We’re more directly concerned with if our members’ lives are materially improved because of our product. As a data scientist working to understand our efficacy, that’s basically all I care about.

This is where you go from metric optimization to something more like scientific experimentation. What I need to understand is our Average Treatment Effect — that is, the expected value of the impact we cause in our users’ lives.

To explain how I might do that, I’m going to dive deep into a kind of causal analysis broken down by Judea Pearl in his fantastic book and in this paper (co-written with Alexander Balke).

This analysis is highly relevant for performing experiments involving a product’s effects on its users, provided that you’re part of a data-driven organization where it’s relatively easy to track app usage patterns. Even so, I’ve yet to see even the most academic of studies in tech use the sort of thinking I’m about to dig into.

Quick word of warning: the deep dive is going to involve a bit of scientific method, a lot of probability theory, a bit of…