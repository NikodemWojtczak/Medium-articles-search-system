Dask Cloud Deployment

If you want to run Dask to speed up your machine learning code in Python, Kubernetes is the recommended cluster manager. This can be done on your local machine using Minikube or on any of the 3 major cloud providers, Microsoft Azure, Google Compute Cloud, or Amazon Web Services.

You are probably familiar with cloud computing since it is pretty much everywhere these days. It is now very common for companies to have all of their computing infrastructure on the cloud, since this reduces their capital expenditure on computing equipment and moves it to operational expenditure, requires less maintenance and also significantly reduces the running cost. Unless you are working with classified information or have very strict regulatory requirements, you can probably get away with running things on the cloud.

Using the cloud allows you to leverage the collective performance of several machines to perform the same task. For example, if you are performing hyperparameter optimization on a neural network and it will need to rerun the model 10,000 times to get the best parameter selection (a fairly common problem) then it would be nonsensical to run it on one computer if it will take 2 weeks. If you can run this same model on 100 computers you will likely finish the task in a few hours.

I hope I have made a good case for why you should make use of the cloud, but be aware that it can get quite expensive if you use very powerful machines (especially if you do not turn them off after using them!)

To set up the environment on the cloud, you must do the following:

Set up a Kubernetes cluster Set up Helm (a package manager for Kubernetes, it is like a Homebrew for Kubernetes cluster) Install Dask.

First run the following

helm repo update

and then

helm install stable/dask

See https://docs.dask.org/en/latest/setup/kubernetes-helm.html for all the details.

Deep Learning on the Cloud

There are several useful tools which are available for building deep learning algorithms with Kubernetes and Dask. For example, TensorFlow can be put on the cloud using tf.distributed of kubeflow. The parallelism can be trivially used during grid optimization since different models can be run on each worker node. Examples can be found on the GitHub repository here.

What do you use?

For my own research (I am an environmental scientist) and in my consulting work (machine learning consultant) I regularly use either JupyterHub, a Kubernetes cluster with Dask on Harvard‚Äôs supercomputer Odyssey, or I will run the same infrastructure on AWS (no real prejudice against Azure or the Google Cloud, I was just taught how to use AWS first).

Example Cloud Deployment on AWS

In this section, I will run through the setup of a Kubernetes Cluster running Dask on AWS. The first thing you need to do is set up an account on AWS, you will not be able to run the following lines of code unless you already have an account.

First, we download the AWS command line interface and configure it with our private key supplied by AWS. We then install Amazon‚Äôs Elastic Container Service (EKS) for Kubernetes using the brew commands.

pip install awscli

aws configure

brew tap weaveworks/tap

brew install weaveworks/tap/eksctl

Creating a Kubernetes cluster is now ludicrously simple, we only need to run one command, but you should specify the cluster name, the number of nodes, and the region you are in (in this case I am in Boston so I choose us-east-1 ) and then run the command.

eksctl create cluster --name=cluster-1 --nodes=4 --region=us-east-1

Now we must configure the cluster with the following commands:

kubectl get nodes

kubectl --namespace kube-system create sa tiller

kubectl create clusterrolebinding tiller --clusterrole cluster-admin --serviceaccount=kube-system:tiller

Now we set up Helm and Dask on the cluster

helm init --service-account tiller

Wait two minutes for this to complete and then we can install Dask.

helm version

helm repo update

helm install stable/dask

helm status agile-newt

helm list

helm upgrade agile-newt stable/dask -f config.yaml

helm status agile-newt

A few more Kubernetes commands.

kubectl get pods

kubectl get services

For more details and a shell, you will need a command like this. Your exact pod names will be different.

kubectl get pod agile-newt-dask-jupyter-54f86bfdd7-jdb5p

kubectl exec -it agile-newt-dask-jupyter-54f86bfdd7-jdb5p -- /bin/bash

Once you are in the cluster, you can clone the GitHub repository and watch Dask go!

Kaggle Rossman Competition

I recommend that once you have got the Dask cloud deployment up and running you try running the rossman_kaggle.ipynb . This is example code from the Kaggle Rossman competition, which allowed users to use any data they wanted to try and predict pharmacy sales in Europe. The competition was run in 2015.

The steps in this notebook run you through how to set up your coding environment for a multilayer perceptron in order to apply it to a parallel cluster and then perform hyperparameter optimization. All of the steps in this code are split into functions which are then run in an sklearn pipeline (this is the recommended way to run large machine learning programs).

There are several other examples on the repository that you can run on the parallel cluster and play with. Also, feel free to clone the repository and tinker with it as much as you like.

Where can I learn more?

To learn more about Dask, check out the following links:

To learn more about Dask with Kubernetes:

To learn more about Helm:

If you are struggling to work through any of the above steps, there are multiple other walkthroughs that go through the specifics in more detail:

For setting up the cluster on the Google Cloud (sadly could not find one for Microsoft Azure) check these links out:

Now you should have a working parallel cluster on which to perform machine learning on big data or for big compute tasks!

Thanks for reading! üôè