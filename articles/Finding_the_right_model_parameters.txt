Something we immediately see in the 10 random images is the difference between digits of any one type too. Take a look at all the 4 in the above 10 images. The first one is bold and straight, the second one is bold and diagonal while the third is thin and diagonal. It’ll be really amazing if the model could learn from the data and actually detect all the different styles for 4 .

Applying machine learning

I decided to use the Random Forest Classifier to train on the training data and predict on the test data. I used the default values for all parameters.

Next, using the prediction, I calculated the accuracy and confusion matrix.

The model achieved an accuracy of 94.4%. The confusion matrix shows that the model was able to predict a lot of images correctly. Next, I decided to tweak the model parameters to try and improve the result.

Parameter Tuning

To identify the best combination of parameter values for the model, I used GridSearchCV . It’s a method provided by the sklearn library which allows us to define a set of possible values we wish to try for the given model and it trains on the data and identifies the best estimator from a combination of parameter values.

In this particular case, I decided to select a range of values for a few parameters. The numbers of estimators could be 100 or 200, maximum depth could be 10, 50 or 100, minimum samples split at 2 or 4 and maximum features can be based on sqrt or log2 .

The GridSearchCV expects the estimator which in our case is the random_forest_classifier . We pass the possible parameter values as param_grid , and keep the cross-validation set to 5. Setting verbose as 5 outputs a log to the console and njobs as -1 makes the model use all cores on the machine. Then, I fit this grid and use it to find the best estimator.

Finally, I use this best model to predict the test data.

Taking a look at the accuracy above, we see that the accuracy improved to 97.08% from 94.42% just by changing the parameters of the model. The confusion matrix also shows that more images were classified correctly.

Machine learning is not just reading the data and applying multiple algorithms till we get a good model to work with but it also involves fine tuning the models to make them work best for the data at hand.

Identifying the right parameters is one of the essential steps in deciding which algorithm to use and making the most of it based on the data.

Conclusion