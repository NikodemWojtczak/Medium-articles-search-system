Member-only story Verifying the Assumptions of Linear Regression in Python and R

Linear regression is one of the most basic machine learning algorithms and is often used as a benchmark for more advanced models. I assume the reader knows the basics of how linear regression works and what a regression problem is in general. That is why in this short article I would like to focus on the assumptions of the algorithm — what they are and how we can verify them using Python and R. I do not try to apply the solutions here but indicate what they could be.

In this article, I mainly use Python (in Jupyter Notebook), but I also show how to use rpy2 — an ‘interface between both languages to benefit from the libraries of one language while working in the other’. It enables us to run both R and Python in the same Notebook and even transfer objects between the two. Intuitively, we need to have R installed on our computer as well.

Disclaimer: Some of the cells using rpy2 do not work and I have to ‘cheat’ by running them in R to show the results. This is mostly the case for cells using ggplot2 . Nonetheless, I leave the code in this cell. Let me know in the comments if this works for you :)

Let’s start!

1. Data