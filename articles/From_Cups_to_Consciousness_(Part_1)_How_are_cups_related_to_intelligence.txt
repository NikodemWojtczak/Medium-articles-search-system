The why, what and how of cup-picking

Start small, start simple. Let’s train embodied agents to navigate through realistic 3D house environments, while picking up cups, and let’s increase the speed (dramatically) over time. As you read this, there are armies of PhDs attempting to program hand-like grippers to pick up arbitrary objects, and legions of industry researchers and engineers programming robots to do increasingly complicated tasks; we’ll start here too.

We intend to iterate quickly, meting-out task configurations that require an agent to understand natural language instructions, that require our agent to communicate, that require our agent to understand. Together, instruction, environment and nascent common sense guide him to accomplish tasks defined in response to our deepest desires, e.g. “pick up the cup”.

Note: Example of task “place cup into the sink” within the AI2Thor environment (see 3D environments later on)

Natural language-instructed cup-picking, as we define it, involves a combination of Reinforcement Learning (RL), Computer Vision (CNN architectures) and Natural Language Processing (NLP) to land in the realm of language grounding.

What is this mythical language grounding of which you speak? Well, grounding establishes concepts beyond the physical presence of objects, i.e. using abstract symbols or representations, and then “grounds” them towards some meaning represented in the real world. Natural language itself is one such symbolic system.

To illustrate this we can use the concept of “dog” as an example. When you read the word “dog” in this document, you likely have a clear picture of an animal with 4 legs, fur and other features that weren’t mentioned. That is, we have a “common ground” or understanding of what a dog is, and can discuss the concept without needing to carry an example around with us all the time. We have grounded the concept of “dog” with language, i.e. we use the word as an abstract equivalent of the animal. But it could be any other arbitrary symbol that we agreed upon, not just a word, and not necessarily the letters d-o-g together. Language is often how we understand another’s thought process, it will also allow us to communicate with the agent.

Any true intelligence (likely) requires an ability for language, whether shared or internal, as well as the agent’s embodiment within the real world. Said agent could then adapt their internal goals and priorities based on the situation.

Language instructions are one of the ways in which we can train a reinforcement learning system, or policy, to accomplish multiple tasks. We chose it because it makes human-agent communication more convenient, while also enabling multi-task learning.

Recent work, like Devendra Chaplot’s, showed that the foundations of language grounding are already within reach in the ViZDoom environment. For instance, if you place an agent in a room containing several objects in randomised positions. Depending on the language instruction given as input at the beginning of each episode, the agent learned to navigate to the particular object while avoiding the others, e.g. “go to the small green torch”. DeepMind also contributed by adding relational instructions, e.g. “the object next to” or “in the green room”, to this task in their lab environment.

Note: Two successful cases of task-oriented language grounding in 3D environments. Left: DeepMind’s grounding modules in Lab. Right: Gated-Attention in ViZDoom. More complicated tasks have been thought of and performed since the work in these papers e.g. “Place the cup into the microwave and turn it on”

This involves multi-modal inputs — vision and language (see our publication on ‘Multi-Modal Methods’) — since the agent will have to use the natural language symbolic system to establish the meaning of the word “cup” as he observes cups in the environment. And that “pick up” actually defines a specific goal in the real world. From here, the symbol of “cup” can be then be mapped-to a particular desire of, or “meaning” for, an agent — a burning desire to go find a cup within his visual system. Such desires are only the beginning. Should our agent have limbs, then he may wish to manipulate the cup and engage his haptic feedback systems.

Our agent shall learn the smooth roundness of a cup and associate the symbol of “cup” to this smooth roundness which he is particularly fond of. He will begin to understand what is “cup-like”. He will have unknowingly grounded himself in the meaning of ‘cups’ and have begun his journey From Cups to Consciousness.

Viva la Robo-lution, Oui?

All griefs with a cup of tea are less, by instagram handle mizumitodepapu

For a machine to ever achieve this dream it would need a world to play with, i.e. an environment. To date, robots have been stuck in strictly controlled environments, mostly imprisoned within factories. The upcoming robot revolution is inevitable with the quickening development of learning machines. Machines which can handle ambiguity, as well as the complex and dynamic environments with changing requirements that our homes represent. Most people would welcome a robot to relieve us from mundane tasks like vacuuming, cleaning and setting the table. And the list goes on.

So what is a good starting point for all of this? Can we finally move away from simplistic 2D Atari games as the test bed for our strongest RL algorithms? The short answer is yes…

Training and experimenting with our agents in the real world will be cumbersome, slow and difficult. However, by having an accurate and realistic enough simulation of typical rooms, we can train thousands of agents simultaneously with tasks relevant to the real world. It is also possible to train for rare edge cases that we couldn’t possibly handle or recreate. All of which can be done much faster than real time.

Our goal is, therefore, to start with simulated but realistic 3D household environments, e.g. kitchens and living rooms. With these we can create tasks that better represent day-to-day problems involving a person’s most common requests (“make me tea”, “clean the kitchen”, “find my favourite cup”). To deploy these systems in our homes, we need to transfer knowledge and skills from the simulation to the real world.