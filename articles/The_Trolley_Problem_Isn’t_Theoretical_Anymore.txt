You are the conductor of a run-a-way trolley that is hurtling down its track at 85 miles an hour, heading straight for a group of young boys playing on the tracks, blissfully unaware of their impending doom. You realize that you can pull a lever to switch the trolley to an alternate track, saving the lives of these boys. Before you pull the lever though, you see there is a young girl who is playing on the tracks of the alternate route. Pulling this lever would mean ending her life. You have ten seconds until it is too late to decide…

What do you do?

The Trolley problem was a thought experiment first introduced by Philippa Foot in 1967. In 1984, this problem was reintroduced in an academic paper by Dr. JJ Thomson. It has been cited over 1300 times.

The good news is that discussions about ethics are becoming more common in computer science classrooms at universities. Engineers are finally beginning to discuss problems about values and fairness when it comes to digital systems and algorithms. What aren’t as highly discussed though, are the consequences — intended or not — of discriminatory systems and biased algorithms that are already in effect and being used by humans every day.

The trolley problem is already being played out by companies like Tesla, Google, Uber, Lyft, Argo, Embark, and General Motors. The problem goes like this :

If a self driving car finds itself in a situation where it has to swerve to save its driver, but swerving left means hitting a child crossing the street, and swerving right means hitting two elderly women crossing the road — which direction should it swerve?

Previously, Google chose the values of deontology: always hit the smallest object no matter what (there was no difference between a trashcan and a baby in a stroller)*. Tesla opted out of accountability; crowd-source human driving data and mimic human driving behaviors. This includes speeding, swerving, and (sometimes) breaking the law.

Why are CS classrooms discussing algorithms and AI theoretically? The technology is here. It isn’t theoretical anymore. It is time to assess the algorithms that already exist in the growing digital landscape. The ones that make decisions that could negatively or positively impact…