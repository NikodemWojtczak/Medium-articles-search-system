AI Trust, Model Bias & Explainability using IBM Watson Openscale

AI trust, bias and model explainability provide a significant piece in the business puzzle to help organizations get AI projects out of development and put them into production at scale. AI bias and model explainability helps ensure fair and unbiased outcomes while giving business process owners confidence in AI’s ability to augment decision-making. At the same time, it provides a robust framework to ensure that AI maintains compliance with corporate policies and regulatory requirements.

Watson Openscale AI Solutions

A short survey showed that business stakeholders have mixed and confusing feedback regarding their trust to AI applications for various reasons:

94% of companies believe AI is key to competitive advantage.

of companies believe to competitive advantage. 60% see regulatory constraints as a barrier to implementing AI.

see as a barrier to implementing AI. 63% cite availability of technical skills as a challenge to implementation

cite as a challenge to implementation 5% of companies have extensively incorporated AI in offerings or processes.

Furthermore, it is widely known among business owners that there are existing challenges related to bias and explainability:

Very difficult to track and measure indicators of business success in production

indicators of business success in production Impossible to teach subtle domain knowledge into AI models in production

subtle domain knowledge into AI models in production No way to validate if AI models will achieve expected business outcomes

if AI models will achieve expected business outcomes Risk violating regulatory and enterprise governance requirements

Watson OpenScale achieves these goals by focusing on 4 stages of an AI application’s lifecycle: Build, Run, Manage and In-App operations.

Watson Openscale across the data science cycle

At build time, data scientists use their preferred popular open source frameworks and tools while gaining access to toolkits for bias detection and explainability of transactions.

Development and operations teams then scale and manage AI applications using their existing DevOps tools and processes in the runtime environment.

As a result, business users are then able to measure and trace the outcome of individual AI workflows for auditing and regulatory purposes.

Watson OpenScale helps deliver and operate trusted AI apps for business users at scale:

Track and Measure business outcomes in production

a. Define business KPIs and feed into existing business applications to measure business impact

b. Define app contract to evaluate AI models at build time and get metrics to track those in run-time

c. Actionable metrics and alerts through error analysis and descriptive analytics of payload, in runtime

2. Meet regulatory constraints & govern AI in production

a. Simulate business conditions with operations data, validate and approve AI models for production

b. Trace and explain AI decisions for full audit across multiple models in an app

c. AI-powered bias detection and mitigation in run time, to drive fair outcomes

3. Adapt AI to changing business situation in production

a. Collect feedback through existing business apps to teach the AI, in runtime

b. Detect drift in business situations, alert users and trigger actions to mitigate

c. Automatically trigger model retraining pipelines with specific inputs from payload analytics to meet business goals and adapt to new data

Advanced Model Management using Watson Openscale

Indicative example: A bank was fined for unequal treatment of minority customers. Minority customers were given fewer loans and charged a higher interest rate.

How can Watson Openscale help to mitigate this bias in this case in model development?

Step 1: Monitor Predictions, Model Performance and Accuracy

Openscale provides a dashboard which displays model accuracy. Model accuracy is determined using the standard model evaluation approaches (different for various model types).

Monitor Predictions, Performance and Accuracy

Step 2: Provide an explanation for model predictions

We can use the explainability feature to understand why certain predictions are made. The two main components of explainability are:

Predictor Importance: Which factors/predictors influence the prediction

Statistical Significance: Identify the statistical importance of each predictor

Constrastive Explanation: which features do we need to change in order to control the prediction

Model Predictions Explainability

Step 3: Monitor for unfair predictions and automatically correct them

i. Define protected fields: typically demographic information about a customer, such as race, age, gender, population segment

ii. Define the context: number of records to use for determining the threshold i.e. evaluate every 100 approvals or every 1000 loan applications

iii. Define a threshold for bias, defined as a percentage of minority approvals compared to approvals of majority. Optionally, OpenScale can “de-bias” the model, i.e automatically correct the results:

De-biased results are automatically logged in the database in addition to model scoring results

The debiased results don’t have to be used in production — they can be used for review or audit

Biased Prediction Monitoring and Mitigation

Auto Bias Mitigation

Description

Models embedded in production need to make fair decisions and can not be biased in their recommendations. Those that they exhibit bias need to be corrected without interfering in current path of predictions to application.

How does it work?

Given an input record we send it to the Bias Detection Model to find out if the model is likely to act in a biased manner on this record

Once we have identified a record for which the model is likely to be biased, we fix it by changing the prediction

Auto-debias trains a shadow model executing in the background to generate trust prior to deployment in production

Most of the industries are embracing AI taking into account AI Model Bias, Model Explainability and Trust.

De-Bias Modeling Process

Value Proposition

Configuration of bias mitigation to run alongside the current deployed model, this provides de-biased outputs without affecting the current predictions that are being served Visualization of the de-biased output in the UI, take action to modify data sets based on recommendations and retrain model with new data set Usage of automatically generated de-biased model end point to score inputs

Bias Mitigation De-biased Output

Industry Use Cases in Model Bias and Explainability

Industry-wide use cases leveraging on Watson Openscale from telecom to financial services and healthcare:

1.Telecom: Predictive Maintenance

Effectively maintaining physical assets and infrastructure is essential for telco industry — asset failure can lead to service outages, a key cause of customer churn. Maintenance prioritization is an expensive and difficult process, and it’s often difficult to catch asset failure in the field before it leads to a problem on the network. Machine learning offers an opportunity to predict failure based on sensor data before a problem occurs.

Predictive maintenance of network infrastructure can prevent outages that lead to costly customer churn, but training a model on historical asset data is difficult because failures tend to be rare — training a predictive model can be time consuming, and even after it’s trained, it may not accurately perform in all failure scenarios

Watson OpenScale’s runtime monitoring features allow teams to track performance of their models in the field, on real data, to ensure continued performance — and guide retraining when necessary. OpenScale’s traceability features also help engineers and technicians capture information critical for an audit trail, so the organization can more easily connect preventative maintenance actions taken because of the model with key business outcomes — like failure prevention and increased customer satisfaction.

2. Insurance: Underwriting Risk Modeling

The insurance industry market landscape is becoming increasingly competitive. Companies are trying to streamline their processes with the help of data science and AI — and insurance underwriting is a prime target for AI insights. Traditional underwriting methods rely on complex rules-based processes and expensive manual analysis, whereas machine learning models can analyze complex interactions among diverse data to deliver risk scores.

Risk assessment models trained on historical customer and claims data can help underwriters make more consistent and accurate decisions. These models can provide price suggestions for individual customers based on different features in their profile.

Watson OpenScale’s explainability features allow underwriters and regulators to see the exact features prioritized by these risk assessment models, on a decision-by-decision basis. During a Department of Insurance audit, commissioners can review model lineage, inputs, and outputs for each decision in business-friendly language. Its bias detection and mitigation features help underwriters ensure that these models continue to make fair decisions after they’ve been deployed.

3. Financial Services: Credit Risk Modeling

Traditional lenders are under pressure to expand their digital portfolio of financial services to a larger and more diverse audience, which requires a new approach to credit risk modeling. To provide credit access to a wider and riskier population, applicant credit histories must expand beyond traditional credit — like mortgages and car loans — to alternate sources, such as utility and cell plan payment histories, plus education and job titles.

These additional features increase the likelihood of unexpected correlations that introduce bias based on an applicant’s age, gender and other personal traits. The data science techniques most suited to these diverse datasets can generate highly accurate risk models but at a cost — such models are black boxes whose inner workings are not easily understood.

Banks and credit unions need to be able to check their credit risk models for bias, not just during training but also after these models are deployed. And in order to be compliant with regulations like the Equal Credit Opportunity Act, they need to be able to explain why their models make individual credit decisions.

Watson OpenScale’s bias detection and mitigation features allow risk and governance officers to monitor bias within their models at runtime. And Watson OpenScale’s explainability support provides loan officers and credit analysts with post-facto explanations for model decisions which provide high accuracy in credit risk modeling.

4. Supply Chain: Effective Demand Forecasting

Effective demand forecasting is essential to keeping operational costs down while still meeting consumer demand — but it’s very difficult. Companies aren’t equipped to deal with the volume and diversity of data needed to account for real-time changes in demand. Forecasts that can’t adapt to constantly-changing variables in today’s market can lead to multimillion-dollar miscalculations, severely damaging a company’s bottom line

Demand forecasters must constantly monitor the performance of their deployed models to prevent miscalculations that could cost their organizations millions of dollars in lost revenue. The data these models rely on are not stationary, and the statistical properties of their distributions will keep shifting as new actuals come in.

Watson OpenScale’s runtime monitoring features allow demand planners to track performance of their deployed models in production, so they can ensure accuracy and identify skewed results and inherent bias in the data.

5. Healthcare: Disease Outcome Prediction

Specific diseases are so complex and difficult to identify early, as its symptoms overlap with those of other common illnesses. Mortality from sspecific disease diagnosis increases every hour that treatment is delayed — so it is critical for doctors and nurses to be able to catch them before patients go into disease shock. Being able to identify those patients who are at highest risk can help clinicians prioritize care. Machine learning models can be trained on hospitalization data and patient data to identify high-risk patients and predict death outcomes. The algorithms and methods used to build accurate models, such as XGBoost gradient boosted trees, do sometimes behave like black boxes.

Watson OpenScale’s explainability features provide a breakdown of the specific patient and hospitalization characteristics that contribute to the decision for each prediction that is made. These results are displayed in a language that the clinicians caring for the patient can understand, increasing their trust in the predictive models and helping them make better care decisions. OpenScale also provides traceability features and runtime monitoring, so the hospital has an audit trail for all patient care decisions that are made and can track the performance of these models over time.

Disclaimer: The views expressed here are those of the article’s author(s) and may or may not represent the views of IBM Corporation. Part of the content on the blog is copyright and all rights are reserved — but, unless otherwise noted under IBM Corporation (e.g. photos, images).