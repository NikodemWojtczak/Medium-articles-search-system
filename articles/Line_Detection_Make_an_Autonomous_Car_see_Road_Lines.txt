Step by step you can turn a video stream into a line detector via Computer Vision

Motivation

Fully self-driving passenger cars are not “just around the corner”. Elon Musk claims that Teslas will have a “full self-driving” capability by the end of 2020. Especially, he says that Tesla’s hardware is already ready for Autonomous drive, and what is left is just an update on their current software, which many brilliant scientists are working on it.

The first instinct to us, humans, as drivers, is probably to look in front of us and decide where should the car move; at which direction, between which lines, etc. As every Autonomous Vehicle comes with a camera in a front, one very important task its to decide the border in which the car should move in between. For humans, we draw lines on the roads. Now we will teach an Autonomous Vehicle to see these lines. I promise it will be fun :)

Acknowledgment — References

The majority of these projects are motivated by Deep Learning for Self-Driving Cars course of MIT and Udacity’s Self-Driving Car Engineer. The latter is a great start to learn and expand your technical knowledge of the field.

Agenda

We will design the hole pipeline step-by-step, in which we will motivate why we are doing it.

• Grayscale transform

• Gaussian Blur

• Canny Edge Detection

• Mask a region of interest

• Hough lines Detector

• Find the Road Lines

The complete code can be found here.

Here we will take it to step by step, providing snaps of the whole code. However, some parts were omitted, as it will make the post very heavy and distract us from our goal. Thus, for any additional information, please refer to the above repository.

Step 0: Reading an Image

With the help of matplotlib we can easily load any image in our python script as a three-dimensional tensor C-H-W (color Channels, Height and Width of image)