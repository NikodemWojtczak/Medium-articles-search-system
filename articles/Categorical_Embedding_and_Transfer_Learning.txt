Introduction

A lot of machine learning algorithms can not deal with categorical variables directly unless they are converted to numbers. However, the problem is that their performance varies significantly by the way these categorical variables are encoded into numbers. This article explores the problem of categorical encoding and gives a glimpse of the old and new methods.

Categorical Variables

A categorical variable is a variable that can take one of the possible fixed and mostly limited set of values. They are associated with features that are qualitative and thus cannot be measured. For example, the day of the week is a categorical variable that can take 7 discrete values. The words/tokens of any language are categorical variables. Machine Learning algorithms are devoted to working with numbers so we have to convert these categorical variables to numbers to please the algorithms. This process is full of pitfalls and we run the risk of losing a lot of information.

Letâ€™s take a look at a couple of common ways to convert categories into numbers and the problems that are associated with them.

Label Encoding

In this process, we assign a discrete number to each unique category using some defined process. For example, we can sort the variables in order of the number of occurrences and number them in increasing order. Another way is to randomly assign a number to each unique category.

Simple Label Encoder

In the above example, the days are labeled in the order of their appearance in the data. The major problems here are:-

Natural ordering is lost Common relationships between categories are not captured. (For example, Saturday and Sunday together make a weekend and hence should be closer to each other)

One Hot/Dummy Encoding

In this scheme, we split the categorical variable into separate binary variables (1 variable for each unique category) such that each new variable is set to 1 when the example belongs to a particular category and 0 otherwise. The below example will make things clear.