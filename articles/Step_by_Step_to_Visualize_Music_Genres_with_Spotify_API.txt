Step by Step to Visualize Music Genres with Spotify API Panda · Follow Published in Towards Data Science · 7 min read · Feb 18, 2019 -- 1 Share

Source: OpenClipart-Vectors on Pixabay

You are what you listen to. Everyone has his/her favorite musicians and those musicians usually are good at certain types of music. We can easily classify a song as Blues, Jazz or Country music, so what is the implication behind it? Can we tell, or see, the difference of music with data? Thanks to the open API from Spotify, we can understand different aspects of music, including tempo, key and audio features, and build up web applications to answer our questions efficiently.

In this article, we use R Shiny as an interface to communicate with Spotify API and host it on shinyapps.io. The website is accessible through the link here. However there are some limitations for shinyapp.io — 25 active hours per month for free. If you cannot connect to it properly, please try it next month. Otherwise, if you have installed R, the following command can run it on your own environment.

shiny::runGitHub("Music_ANA","BarryPan")

There are two sections in the article. The first section is about the steps to build up the visualization application; in the second part, we can share how it could be helpful for us to determine different music genres. You will be able to build up your own music analytical tool and have more insights with Spotify API after the reading.

Step 1: Read the API document

First of all, we need to understand our data and what information we have. Spotify provides thorough explanation to its API, and it is really critical for a developer or analyst to read it before starting to do anything. Based on our experience, we believe that tempo, keys and audio features are decisive factors for recognizing music genres, and they should be what we are going to visualize.

In Spotify API, it provides many audio features. We choose certain features and the definitions are showing below: