Section 2

Architecture Diagram

Install the Gunicorn Python package:

$ pip install gunicorn

Configure gunicorn.conf file to configure Gunicorn web server.

We have configured Gunicorn web server to listen on port 5000 and run the main.py file from the app directory.

Configure supervisord as monitoring process:

Supervisord allows a user to monitor and control several processes on UNIX-like operating systems. Supervisor will look after the Gunicorn process and make sure that they are restarted if anything goes wrong, or to ensure the processes are started at boot time.

It will run NGINX reverse proxy server and keep a monitor on it. If anything fails it will automatically restart the server and run NGINX command.

Set up NGINX server:

Open up a server block and set NGINX to listen on the default port 80 . Users can set the server name to handle the request.

Create Dockerfile:

I have divided Dockerfile into 5 sections. Let’s go briefly into each section:

Create an Ubuntu environment. Install Ubuntu and update the necessary package. Install python, pip, virtual environment, NGINX, Gunicorn, and supervisor. Set up a flask application. Make a directory “/deploy.app”. Copy all files from the “app” folder to “/deploy/app” folder. Install all the required python packages. Set up NGINX. Remove default NGINX configuration. Copy flask configuration to NGINX configuration. Create a symbolic link for NGINX flask configuration. Set up supervisord. Make a directory “/var/log/supervisor”. Copy Gunicorn and supervisord configuration to the newly-created directory. Start supervisord process for monitoring.

Build and run docker image to test the production-ready ML web API:

I have created a makefile to run all the commands.

The below Makefile performs two operations:

Create a docker image Run docker image on port 80

Run Makefile:

deploy-local: #build docker image

docker build -t gcr.io/${project_id}/${image_name}:${version} . #run docker image

docker run -d --name ${image_name} -p $(port):$(port) gcr.io/${project_id}/${image_name}:${version}

Test production-ready web API on development machine using Postman on URL: http://127.0.0.1/predict

In the above section, we have learned how to to build and run an ML web API docker image on the development machine.