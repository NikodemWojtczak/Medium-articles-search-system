Photo by Sebastian Pichler on Unsplash

Web crawling, also known as web scraping, data scraping or spider, is a computer program technique used to scrape a huge amount of data from websites where regular-format data can be extracted and processed into easy-to-read structured formats.

Web crawling is commonly used:

Web crawling basically is how the internet functions. For example, SEO needs to create sitemaps and gives their permissions to let Google crawl their sites in order to make higher ranks in the search results. Many consultant companies would hire companies to specialize in web scraping to enrich their database so as to provide professional service to their clients.

It is really hard to determine the legality of web scraping in the era of the digitized era.

Why does web crawling have a negative connotation:

Web crawling can be used in the malicious purpose for example:

Scraping private or classified information. Disregard of the website’s terms and service, scrape without owners’ permission. An abusive manner of data requests would lead web server crashes under additionally heavy load.

It is important to note that a responsible data service provider would refuse your request if:

The data is private which would need a username and passcodes The TOS (Terms of Service) explicitly prohibits the action of web scraping The data is copyrighted

What reasons can be used to sue people?

Your “just scraped a website” may cause unexpected consequences if you used it inappropriately.

HiQ vs LinkedIn

You probably heard of the HiQ vs Linkedin case in 2017. HiQ is a data science company that provides scraped data to corporate HR departments. Linkedin then sent desist letter to stop HiQ scraping behavior. HiQ then filed…