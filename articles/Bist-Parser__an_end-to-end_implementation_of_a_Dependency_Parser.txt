This article is the 2nd and last article on Dependency Parsing. We will give you some easy guidelines for implementation and the tools to help you improve it.

Vocabulary

A TreeBank is a parsed text corpus that annotates syntactic or semantic sentence structure. Dependency TreeBanks are created using different approaches : either thanks to human annotators directly, or using automatic parsers to provide a first parse, then checked by annotators. A common approach consists in using a deterministic process to translate existing TreeBanks into new language through head rules. Producing a high-quality TreeBank is both time-consuming and expensive.

is a parsed text corpus that annotates syntactic or semantic sentence structure. Dependency TreeBanks are created using different approaches : either thanks to human annotators directly, or using automatic parsers to provide a first parse, then checked by annotators. A common approach consists in using a deterministic process to translate existing TreeBanks into new language through head rules. Producing a high-quality TreeBank is both time-consuming and expensive. CoNLL-U — Computational Natural Language Learning-Universal is a revised version of the CoNLL-X format. Sentences from TreeBanks are separated, and each word or punctuation mark is disposed on a distinct line. Each of the following items follows the word, separated by tabulations:

–ID: word index in the sentence, starting at 1

–FORM: word form or punctuation

–LEMMA: Lemma or stem of word form

–UPOS: Universal part of speech tag

–XPOS: Language-specific part of speech tag; will not be used in our model

–FEATS: Unordered list of morphological features, defined by Universal Dependencies; indicates the gender and number of a noun, the tense of a verb, etc.

–HEAD: Head of the word, indicates the index of the word to which the current one is related

–DEPREL: Universal Dependencies relation; indicates the relation between two words (subject or object of a verb, determiner of a noun, etc.)

–DEPS: Language-specific part dependencies; will not be used in our model

–MISC: Commentary or other annotation

An example of CoNLL-U format

An Entry is a word, or a punctuation mark in a sentence. It has multiple attributes, defined above. A sentence is typically a concatenation of entries (a word itself is an attribute of an entry: its form), separated by space.

The Implementation

The implementation of the Bist-Parser comes from the authors of its paper. An update has been published on GitHub by Xiezhq Hermann. You can find it here. It works on Python 3.x, with torch 0.3.1 (with or without Cuda). It is very complete and can be used as is. However, in order to adapt the code to your data or upgrade it, you must get through every module, which can be a difficult task. This part of the article will lead you through all files and processes.

Universal Dependencies (UD) is an open-community framework for grammatical annotation. It provides corpora and tools that greatly help to develop a Dependency Parser.

From UD, you can download a corpus of sentences of your choice (in any language available, even Old French!), use them as is, and start training your Bist-Parser with this type of command:

python src/parser.py --outdir [results directory] --train training.conll --dev development.conll --epochs 30 --lstmdims 125 --lstmlayers 2 [--extrn extrn.vectors]

You can detail hyperparameters here, caught by the model thanks to the file parser.py

As you may know, when you train a model on a corpus, the model is biased towards this corpus. You could train your model on multiple corpora in order to generalize it more. Several techniques allow you to increase scores, with TreeBank Embedding as an example. Here, we have just concatenated some TreeBanks, without any further processing.

utils

Create a ConllEntry class: every entry has well-known attributes: id, form, lemma, Universal PoS tag, language Specific PoS tag, morphological features, head of current word, dependency relation, enhanced dependency relation and commentary. These attributes are defined from the Universal Dependencies CoNLL-U format. This format is useful for the model to understand what its inputs are, and what it should predict.

class: every entry has well-known attributes: id, form, lemma, Universal PoS tag, language Specific PoS tag, morphological features, head of current word, dependency relation, enhanced dependency relation and commentary. These attributes are defined from the Universal Dependencies CoNLL-U format. This format is useful for the model to understand what its inputs are, and what it should predict. Read a CoNLL-U file and transform each sentence into a ConllEntry.

Count vocabulary: This function creates a Counter of ConllEntry attributes and allows you to know how these attributes are distributed through your dataset. If you want to determine the most frequent words or relations in your dataset, this function can be useful.

mstlstm

This file contains your model. All your hyper-parameters and most of your monitoring work happen in this file.

The method forward iterates through each entry in the sentence. It first computes the vectors for each entry attribute. With our model, we get multiple vectors that describe the word, the PoS tag and the feats. Those vectors are then concatenated to form a vector with a bigger dimension for each entry. These entries are then concatenated together to form the sentence vector.

First, it converts entries into vectors. Here, the principal attributes are the embedding of words, lemmas (onto) and PoS tags (pos). However, we advise you to add as many features as possible. For example, you may have access to features of words that indicate whether the noun is singular or plural, its gender, or tense… Embedding these features allows your BiLSTM to find many more patterns.

Evolution of PoS embedding on two dimensions

Then, it feeds the BiLSTM with these vectors (for = forward, back = backward). Line 52 evaluates the scores of the sentence. This is the part where the full Weighted Digraph is created. On line 57, it evaluates the relation score. This is an interesting trick in this model: rather than evaluating all the possibilities at the same time (|possibilities|=|arcs|.|labels|, which is way too high), it predicts the dependencies first, then the relations.

We will see about errs, lerrs and e later.

In the illustrations below, you can see the evolution of dependency evaluation through batches. A dark blue cell corresponds to a weighted arc. The example comes from a typical French sentence, “Les commotions cérébrales sont devenu si courantes dans ce sport qu’on les considère presque comme la routine.” You can spot spelling mistakes in the sentence; this is not rare in TreeBanks.