Member-only story Cleaning Web-Scraped Data With Pandas and Regex! (Part I)

|| I || Introduction

Now that I’ve started programming on a daily basis, I decided to invest in a laptop that would allow me to multi-task smoothly and run all my desired applications the way I’m used to.

I own a Unix-based Macbook, but its M3 processor just doesn’t cut it when I’m working on projects that require processing a lot of images or videos. I also have a Windows notebook from work with a decent i5, but after using it, I’ve realized that my needs are much higher.

However, I’m not about to just drop $2000 any machine with good specs. I actually want to understand how the components/specs of a laptop (Size, Storage, RAM, Processor, etc.) contribute to form an overall representation of the Lapton in the market at a certain price. For example, I want to derive:

The relationship between different components of the laptop and its price.

The relationship between product ratings and specific components.

A comparison of different brands and their similar products.

There are a number of insights I could derive from scraping product data, and I will eventually develop an algorithm to find the right Laptop given a number of inputs.

|| II || Web Scraping

Thanks to a friend, I found out about the “Web Scraper” extension on Google Chrome. You can find it here.

The extension helped me collect the required data for Laptops on Amazon.

This web-scraper does what most others do: it collects information we want from the page source. Websites don’t always make it easy for you to extract data from their pages, therefore you would need to clean the extracted data before you can use it for any kind of analysis.

Photo by The Creative Exchange on Unsplash

So what do I mean by “cleaning” the data?

Often, the data will have some impurities, such as NaN (empty) values…