Deep Learning enables us to perform many human-like tasks, but if you’re a data scientist and you don’t work in a FAANG company (or if you’re not developing the next AI startup) chances are that you still use good and old (ok, maybe not that old) Machine Learning to perform your daily tasks.

One characteristic of Deep Learning is that it’s very computationally intensive, so all the main DL libraries make use of GPUs to improve the processing speed. But if you ever felt left out of the party because you don't work with Deep Learning, those days are over: with the RAPIDS suite of libraries now we can run our data science and analytics pipelines entirely on GPUs.

In this article we’re going to talk about some of these RAPIDS libraries and get to know a little more about the new Data Science PC from Maingear.

Why do people use GPUs anyway?

Generally speaking, GPUs are fast because they have high-bandwidth memories and hardware that performs floating-point arithmetic at significantly higher rates than conventional CPUs [1]. GPUs' main task is to perform the calculations needed to render 3D computer graphics.

But then in 2007 NVIDIA created CUDA. CUDA is a parallel computing platform that provides an API for developers, allowing them to build tools that can make use of GPUs for general-purpose processing.

GPUs had evolved into highly parallel multi-core systems, allowing very efficient manipulation of large blocks of data. This design is more effective than general-purpose central processing unit (CPUs) for algorithms in situations where processing large blocks of data is done in parallel — CUDA article on Wikipedia [2]

Processing large blocks of data is basically what Machine Learning does, so GPUs come in handy for ML tasks. TensorFlow and Pytorch are examples of libraries that already make use of GPUs. Now with the RAPIDS suite of libraries we can also manipulate dataframes and run machine learning algorithms on GPUs as well.

RAPIDS

RAPIDS is a suite of open source libraries that integrates with popular data science libraries and workflows to speed up machine learning [3].

Some RAPIDS projects include cuDF, a pandas-like dataframe manipulation library; cuML, a collection of machine learning libraries that will provide GPU versions of algorithms available in sciKit-learn; cuGraph, a NetworkX-like accelerated graph analytics library [4].

Pandas and sciKit-learn are two of the main data science libraries, so let’s get to know more about cuDF and cuML.

cuDF: dataframe manipulation

cuDF provides a pandas-like API for dataframe manipulation, so if you know how to use pandas you already know how to use cuDF. There is also the Dask-cuDF library if you want to distribute your workflow across multiple GPUs [5].

We can create series and dataframes just like pandas:

import numpy as np

import cudf s = cudf.Series([1,2,3,None,4]) df = cudf.DataFrame([('a', list(range(20))),

('b', list(reversed(range(20)))),

('c', list(range(20)))])

It’s also possible to convert a pandas dataframe to a cuDF dataframe (but this is not recommended):

import pandas as pd

import cudf df = pd.DataFrame({'a': [0, 1, 2, 3],'b': [0.1, 0.2, None, 0.3]})

gdf = cudf.DataFrame.from_pandas(df)

We can also do the opposite and convert a cuDF dataframe to a pandas dataframe:

import cudf df = cudf.DataFrame([('a', list(range(20))),

('b', list(reversed(range(20)))),

('c', list(range(20)))]) pandas_df = df.head().to_pandas()

Or convert to numpy arrays:

import cudf df = cudf.DataFrame([('a', list(range(20))),

('b', list(reversed(range(20)))),

('c', list(range(20)))])

df.as_matrix() df['a'].to_array()

Everything else we do with dataframes (viewing data, sorting, selecting, dealing with missing values, working with csv files and so on) works the same:

import cudf df = cudf.DataFrame([('a', list(range(20))),

('b', list(reversed(range(20)))),

('c', list(range(20)))]) df.head(2)

df.sort_values(by='b')

df['a']

df.loc[2:5, ['a', 'b']] s = cudf.Series([1,2,3,None,4])

s.fillna(999) df = cudf.read_csv('example_output/foo.csv')

df.to_csv('example_output/foo.csv', index=False)

About performance, just to give an example, loading a 1gb csv file using pandas took 13 seconds and loading it with cuDF took 2.53 seconds.