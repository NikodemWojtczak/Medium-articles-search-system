If you are in data and analytics industry, you must have heard of the burgeoning trend “data-lake” which, on simpler notes, represents a storage strategy that allows organizations to store data from different sources and of different characteristics (size, format and velocity) in one place. Data-lake then becomes an enabler of a number of use-cases like advanced analytics or data warehousing to name a few and generally data is moved to a more specialized store e.g. MPP relational engines or NoSQL to better serve the requirements of a specific use-case. If the platform is being provisioned in a cloud environment like AWS, Azure or GCP then object stores (e.g. S3 for AWS, Azure Data Lake Store Gen2 for Azure) are usually the strongest candidates to provide the foundational physical layer of data-lakes. Once the data is in data-lake, it passes through series of zones/phases/layers to establish semantic consistency in the data and to conform it for optimal consumption.

Usually, as per the reference architecture of data-lake platforms, which is agnostic of which cloud provider you choose, Hadoop (specifically Spark) is employed as a processing engine/component to process the data in data-layer as it progresses through different layers. These processing frameworks are well-integrated with data-lake services, provide capabilities like horizontally scalability, in-memory computation and unstructured data processing which position them as viable options in this context. One generally has a number of choices to use Hadoop distributions in the cloud for instance one can proceed with provisioning IaaS based infrastructure (i.e. AWS EC2 or Azure Virtual machines and installing a Hadoop distribution e.g. vanilla Hadoop, Cloudera/Hortonworks). Alternatively, almost all the cloud providers are providing Hadoop as managed services natively (e.g. ElasticMapReduce (EMR) in AWS, HDInsight/Databricks in Azure, Cloud Dataproc in GCP). Each of the options have their pros and cons. For example with IaaS based implementation, the overhead of provisioning, configuring and maintaining the cluster by yourself becomes a strong concern for many. Also, the intrinsic propositions of Cloud like elasticity and scalability pose a challenge in IaaS based implementation.