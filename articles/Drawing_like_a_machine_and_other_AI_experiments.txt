Photo by Ms Jemini Photos on Unsplash

Have you ever wondered what is hidden behind the ‘artificial intelligence’ term? A glimpse of the possibilities that ‘machine learning’ brings to us can be visualized using online apps prepared by Experiments with Google. In general, it is a group of designers and engineers who create fun experiments as a way of introducing these concepts based on Google’s technology. Some of them are cute and quick web games, others are more advanced, but all of them were done to make understanding new technologies more accessible to other people.

Quick, Draw! is an online game similar to word-guessing charade like Pictionary. The difference is that you are not playing it with your friends but with the computer. You have 20 seconds to draw a picture based on displayed word and in the same time the artificial intelligence is trying to guess what you are drawing based on all lines that you are scribbling on the screen.

Best onion drawing ever

In the beginning of this project the model was intentionally not perfectly trained, so it would be more entertaining. All of the doodles made by users are contributing to creating a well-described dataset full of drawings. The neural networks used to build this model are learning more and more every day thanks to them. The dataset consisting of over 50 million pictures is available online. It inspired many researchers to built new models, publish research papers and perform various analysis like how bad you can be at drawing flamingos. Below you can see an overview how differently people are drawing a giraffe.

Example of giraffe drawings made by users

And here is the official video describing the website:

Another example of drawing app is AutoDraw — thanks to this app you can draw best illustrations in your life. The site is advertising as ‘Fast drawing for everyone’ and it is pretty accurate description. Have you ever planned to create a fliers for a party but your lack of drawing skills would always result in using pre-made templates?

Here you can see my drawing skills again (or lack of them)

On this website you can sketch whatever you want and the computer would try to help you with this task. Adding more detail to your cartoon will result in more accurate prediction from the computer’s side, and if you are satisfied with it, you can simply exchange your drawing with the one proposed by site.

The AutoDraw model was built on top of the dataset collected in Quick, Draw! but the clip arts itself are made by various illustrators and design studios.

Official video of AutoDraw:

On this website, you can actually teach the computer to behave the way that you want it to behave. Using your camera, Teachable Machine lets you teach a machine live in the browser without any coding experience required. This experiment makes it easier for anyone to start exploring how machine learning works.

So, how it works? On the screen you can see the feed from your camera, three big buttons and gifs. Pictures from your camera will be the input for the neural network algorithm to learn from. While making different gestures you have to take the pictures using ‘Train’ buttons. For each type of gesture you need to take at least 30 photos. Those three classes of pictures are associated with the output — first gesture will enable first gif, second and third the following ones. After teaching your neural network you can test it right away. Showing the same gestures as during the teaching phase would result in changing the output.

You can also change the gifs and make the website show ones picked by you. Besides the gifs, the other type of output that you can get is sound and speech — you can choose that instead of showing cats and bunnies the output will result in conversation with computer. This whole process of feeding an algorithm with your data and it learning to properly classify is all what machine learning is about.

One of the apps built on top of the Teachable Machine is Teachable Snake. As you may be guessing, it is a well-known Snake game, but the controllers are the signs that you have to show using your camera. Take a piece of paper, draw an arrow and show the Snake where it has to go to eat all the points!

In this experiment, you can play a piano duet together with the machine. Here you can release all your musical creativity and try to play the best improvised duet along with the artificial intelligence using your laptop keyboard. A.I. Duet is a tool which runs the notes you play through a neural network and tries to accompany you in this adventure. The neural network has been trained with tons of examples of melodies. In traditional programming approach the code would need to have all of possible connections between notes, keys and timing implemented. A.I. Duet model created all rules of melodies from data perspective combining them on its own and now it generates completely new tunes which will match your part.

This experiment combines two big machine learning issues — image recognition and speech synthesis. It starts with the users taking a picture using the camera in their phone of stuff around them. The Giorgio Cam tries to recognize the object and creates a description of what it found. This description is then turned into the rap song lyrics to the music written by Giorgio Moroder. By taking pictures of different things, together with your phone you can become a rap king!

Summary

In general, all of the examples above show how machine learning works — it gathers lots of inputs and learns from it to predict something. Those applications benefit the most when more people are using them and tell what is right or wrong. The more correct data from users is gathered, the more accurate the results will be. There are far more advanced applications of artificial intelligence than rapping camera and playing charades with computer but those are just simple examples which can show you how far we’ve come from counting using the abacus.