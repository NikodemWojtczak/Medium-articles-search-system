Automated Machine Learning(AutoML) is currently one of the explosive subfields within Data Science. It sounds great for those who are not fluent in machine learning and terrifying for current Data Scientists. The way AutoML has been portrayed in the media makes it seem capable of completely revolutionizing the way we create models by removing the need for Data Scientists. While some companies such as DataRobot aim to fully automate the machine learning process, most in the field are creating AutoML as a tool to increase the production of current Data Scientists, and simplify the process for those entering the field to make it more accessible.

AutoML as a tool to fully automate the process is a great idea on paper, but in the real world it introduces many opportunities for bias and misunderstanding. In the past few years, the machine learning field has began to diverge away from “black-box” models, and instead use simpler models that are easier to interpret. Complex models can be hard to decipher and because of this it is hard to know when a model is introducing bias. AutoML now exacerbates this problem of a black box model, by hiding not only the mathematics of the model, but also performing the following in the background:

data cleaning

feature selection

model selection

parameter selection.

With all of the above automated what does that leave for the people using these systems. Other than grabbing a dataset and reading the results, nothing. This level of automation introduces potential problems for both our models and the people interpreting them. While studying to be a Data Scientist three things have become prevalent above all else.

Models are only as good as the data are given and can easily introduce bias if the data is flawed. Machines are very good at maximizing the objective function given by a human, whether or not that objective function is accurate or correct. A large portion of studying for Data Science is dedicated to understanding the model’s algorithm and its results, without this knowledge it is easy to make incorrect inferences about the models results.

The past few years we have seen multiple reports of models in circulation that continually make incorrect/biased predictions. If there is bias in the real world it can easily be increased by not accounting for it properly in the model. AutoML might…