3. Data Overview

The dataset for this project is provided by the authors of the paper themselves which can be found here.

Data comes with 12295 images in total, out of which 10,000 are training images and 2295 are test images.

Data also comes with two txt files: training.txt and testing.txt . These two files holds the information about the path of images, the co-ordinate positions of facial features and 4 other facial attributes:

1st Attribute: Gender[M/F]

2nd Attribute: Smiling/Not Smiling

3rd Attribute: With Glasses/No Glasses

4th Attribute: Pose Variation

3.1 Loading and Cleaning the data

Let’s load the training.txt file and try to understand and analyse the data. When you’ll read the training.txt files using pandas read_csv function using space as a separator, it will not be loaded correctly and that’s because of the reason there is space at the beginning of each line. So, we need to strip that out.

Training.txt file

The following code will do exactly that.

f = open('training.txt','r')

f2 = open('training_new.txt','w')

for i,line in enumerate(f.readlines()):

if i==0:

continue

line = line.strip()



f2.write(line)

f2.write('

')

f2.close()

f.close()

Now, we’ll use this newly created file training_new.txt in the project. Do the same for testing.txt file.

Reading the cleaned training.txt file.

names = ['Path']+list('BCDEFGHIJK')+['Gender','Smile','Glasses','Pose'] train = pd.read_csv('training_new.txt',sep=' ',header=None,names=names)

train['Path'] = train['Path'].str.replace('\\','/')

Here is the meaning of each attribute in the training file.

Path: the path of the image(absolute path)

B: x co-ordinate of right eye centre

C: x co-ordinate of left eye centre

D: x co-ordinate of nose centre

E: x co-ordinate of extreme right point of mouth

F: x co-ordinate of extreme left point of mouth

G: y co-ordinate of right eye centre

H: y co-ordinate of left eye centre

I: y co-ordinate of nose centre

J: y co-ordinate of extreme right point of mouth

K: y co-ordinate of extreme left point of mouth

Gender: whether the person is male/female, 1: Male, 2: Female

Smile: Whether the person is smiling or not, 1: Smile, 2:Not smile

Glasses: whether the person has glasses or not, 1: Glasses, 2: No Glasses

Pose: [Pose estimation ] , 5 categories.

3.2 Visualize the data

Now, let’s visualize some of the images with the facial keypoints.

Code:

#visualising the dataset

images = []

all_x = []

all_y= []

random_ints = np.random.randint(low=1,high=8000,size=(9,))

for i in random_ints:

img = cv2.imread(train['Path'].iloc[i])

x_pts = train[list('BCDEF')].iloc[i].values.tolist()

y_pts = train[list('GHIJK')].iloc[i].values.tolist()

all_x.append(x_pts)

all_y.append(y_pts)

img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)

images.append(img) fig,axs = plt.subplots(nrows=3,ncols=3,figsize=(14,10)) k =0

for i in range(0,3):

for j in range(0,3):

axs[i,j].imshow(images[k])

axs[i,j].scatter(all_x[k],all_y[k])

k += 1 plt.show()

4. Deep Dive

Now, we get the idea of what facial key point prediction is all about. Let’s dive deep and understand the technical details about it.

Takes a image as input and give the co-ordinate of facial features.

It’s a regression problem, as it predict the continuous values i.e co-ordinate of facial landmarks.

Face Alignment, Magic box?

What’s that magic thing in the box which does all of this?

Let’s deep dive more, and understand it.

As of now there are two approaches through which we can solve this problem, one is vanilla computer vision techniques(like viola and jones for bounding box prediction of face), and other one is deep learning based, especially convolutional neural network based.

But what the heck is this convolutional neural network?

Simply put, it’s technique that is used to extract and detect meaningful information from image. If you’re interested in learning more, head over to here.

We’ll take the second route for this problem, that is deep learning based.